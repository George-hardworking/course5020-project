{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1459cbd",
   "metadata": {},
   "source": [
    "# CNGF5020 Project Iï¼šåŸºäºMODISçš„ä¸­å›½å¿åŸŸç«ç‚¹æ—¶ç©ºåˆ†æï¼ˆ2010â€“2019ï¼‰\n",
    "\n",
    "æœ¬é¡¹ç›®æ ¸å¿ƒç›®æ ‡ï¼š\n",
    "- æ•°æ®ï¼šæ•´åˆ 2010â€“2019 å¹´ MODIS ç«ç‚¹ç›‘æµ‹æ•°æ®ä¸ä¸­å›½å¿çº§è¾¹ç•Œï¼ˆ`raw_data/CHN_County/CHN_County.shp`ï¼‰ã€‚\n",
    "- ä»»åŠ¡ï¼š\n",
    "  1) æ„å»ºç«ç‚¹åœ°ç†æ•°æ®é›†ï¼ˆç»çº¬åº¦â†’ç‚¹çŸ¢é‡ï¼ŒWGS84ï¼‰ï¼›\n",
    "  2) ä¸å¿çº§è¾¹ç•Œè¿›è¡Œç©ºé—´å åŠ ï¼›\n",
    "  3) ç»Ÿè®¡å¿åŸŸ-å¹´åº¦/å¿åŸŸ-å¹´æœˆç«ç‚¹æ•°é‡ä¸ FRP æŒ‡æ ‡ï¼›\n",
    "  4) è¿›è¡Œå…¨å›½å¹´åº¦è¶‹åŠ¿ã€å­£èŠ‚æ€§ä¸â€œé«˜ç«ç‚¹å¿â€å¯¹æ¯”ï¼›\n",
    "  5) äº§å‡ºåˆ†æå›¾è¡¨ä¸ç»“æœè¡¨æ ¼ï¼ˆCSV/GeoJSONï¼‰ï¼Œç¡®ä¿å¯å¤ç°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07bb5f",
   "metadata": {},
   "source": [
    "\n",
    "# CNGF5020 Mini Group Project I: å†œä¸šç§¸ç§†ç„šçƒ§è¯†åˆ«  \n",
    "##### å›¢é˜Ÿ: Kaibiao Zhuæœ±æ¥·å½ª    Junye Zhongé’Ÿä¿Šçƒ¨   Hongyue Wuå´æ³“æ¨¾    Yueting Zhangå¼ ç²¤è‘¶  \n",
    "##### ç›®æ ‡: åˆ©ç”¨ MODIS ç«ç‚¹ + ä½œç‰©æˆç†ŸæœŸæ …æ ¼æ•°æ®ï¼Œè¯†åˆ«é»‘é¾™æ±Ÿçœç‰ç±³/å°éº¦æ”¶è·åç„šçƒ§äº‹ä»¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8259510",
   "metadata": {},
   "source": [
    "**Step 1: ç¯å¢ƒè®¾ç½®ä¸è·¯å¾„å®šä¹‰**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb88295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.14 | pandas: 2.3.3 | geopandas: 1.1.1 | shapely: shapely | rasterio: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def show_versions():\n",
    "    print(\n",
    "        \"Python:\", sys.version.split(\" \")[0],\n",
    "        \"| pandas:\", pd.__version__,\n",
    "        \"| geopandas:\", gpd.__version__,\n",
    "        \"| shapely:\", Point.__module__.split(\".\")[0],\n",
    "        \"| rasterio:\", rasterio.__version__\n",
    "    )\n",
    "\n",
    "show_versions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711041fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: f:\\github desktop\\course5020-project\\script\n",
      "FIRE_DIR exists: False\n",
      "COUNTY_SHP exists: False\n",
      "OUT_DIR: f:\\github desktop\\course5020-project\\script\\outputs\n",
      "âœ… è·¯å¾„è®¾ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# è·¯å¾„ä¸è¾“å‡ºç›®å½•\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start=Path.cwd(), markers=('raw_data','requirements.txt','.git')):\n",
    "    p = start.resolve()\n",
    "    while True:\n",
    "        if any((p / m).exists() for m in markers):\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            return start.resolve()\n",
    "        p = p.parent\n",
    "\n",
    "# ç¡®ä¿ BASE_DIR æŒ‡å‘é¡¹ç›®æ ¹ï¼ˆé€‚é… notebook åœ¨ script ç›®å½•ä¸­è¿è¡Œçš„æƒ…å†µï¼‰\n",
    "BASE_DIR = str(find_repo_root())\n",
    "FIRE_DIR = os.path.join(BASE_DIR, 'raw_data', 'satellite_fire_data')\n",
    "COUNTY_SHP = os.path.join(BASE_DIR, 'raw_data', 'CHN_County', 'CHN_County.shp')\n",
    "CROPLAND_DIR = os.path.join(BASE_DIR, 'raw_data', 'cropland_distribution_and_phenological_data')\n",
    "\n",
    "OUT_DIR = os.path.join(BASE_DIR, 'outputs')\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print('BASE_DIR:', BASE_DIR)\n",
    "print('FIRE_DIR exists:', os.path.isdir(FIRE_DIR))\n",
    "print('COUNTY_SHP exists:', os.path.isfile(COUNTY_SHP))\n",
    "print('OUT_DIR:', OUT_DIR)\n",
    "\n",
    "print('âœ… è·¯å¾„è®¾ç½®å®Œæˆ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3501d",
   "metadata": {},
   "source": [
    "**Step2: åŠ è½½å¹¶åˆå¹¶ MODIS ç«ç‚¹æ•°æ® (2010â€“2019)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cafc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–å¹¶åˆå¹¶ 2010-2019 å¹´ MODIS ç«ç‚¹æ•°æ®ï¼ˆå…¼å®¹ä¸åŒåˆ—åç»„åˆï¼‰\n",
    "csv_files = sorted(glob(os.path.join(FIRE_DIR, 'modis_20*_China.csv')))\n",
    "assert len(csv_files) > 0, 'æœªæ‰¾åˆ°ç«ç‚¹CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶åæ¨¡å¼ã€‚'\n",
    "print(\"=== è¯¦ç»†æ–‡ä»¶è¯Šæ–­ ===\")\n",
    "print(f\"FIRE_DIR: {FIRE_DIR}\")\n",
    "print(f\"FIRE_DIR ç»å¯¹è·¯å¾„: {os.path.abspath(FIRE_DIR)}\")\n",
    "print(f\"FIRE_DIR æ˜¯å¦å­˜åœ¨: {os.path.exists(FIRE_DIR)}\")\n",
    "\n",
    "if os.path.exists(FIRE_DIR):\n",
    "    # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶å’Œç›®å½•\n",
    "    print(f\"\\n=== FIRE_DIR ç›®å½•å†…å®¹ ===\")\n",
    "    all_items = os.listdir(FIRE_DIR)\n",
    "    print(f\"æ€»é¡¹ç›®æ•°: {len(all_items)}\")\n",
    "    \n",
    "    csv_files = []\n",
    "    other_files = []\n",
    "    subdirs = []\n",
    "    \n",
    "    for item in all_items:\n",
    "        item_path = os.path.join(FIRE_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirs.append(item)\n",
    "        elif item.lower().endswith('.csv'):\n",
    "            csv_files.append(item)\n",
    "        else:\n",
    "            other_files.append(item)\n",
    "    \n",
    "    print(f\"CSV æ–‡ä»¶ ({len(csv_files)} ä¸ª):\")\n",
    "    for csv in sorted(csv_files):\n",
    "        print(f\"  ğŸ“„ {csv}\")\n",
    "    \n",
    "    print(f\"\\nå­ç›®å½• ({len(subdirs)} ä¸ª):\")\n",
    "    for subdir in sorted(subdirs):\n",
    "        print(f\"  ğŸ“ {subdir}\")\n",
    "        \n",
    "    print(f\"\\nå…¶ä»–æ–‡ä»¶ ({len(other_files)} ä¸ª):\")\n",
    "    for other in sorted(other_files):\n",
    "        print(f\"  ğŸ“ {other}\")\n",
    "    \n",
    "    # æµ‹è¯• glob æ¨¡å¼åŒ¹é…\n",
    "    print(f\"\\n=== Glob æ¨¡å¼åŒ¹é…æµ‹è¯• ===\")\n",
    "    patterns_to_test = [\n",
    "        'modis_20*_china.csv',\n",
    "        'modis_20*.csv', \n",
    "        '*.csv'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns_to_test:\n",
    "        matched_files = glob(os.path.join(FIRE_DIR, pattern))\n",
    "        print(f\"æ¨¡å¼ '{pattern}': åŒ¹é…åˆ° {len(matched_files)} ä¸ªæ–‡ä»¶\")\n",
    "        for f in matched_files:\n",
    "            print(f\"  âœ… {os.path.basename(f)}\")\n",
    "\n",
    "# æ£€æŸ¥å½“å‰å·¥ä½œç›®å½•\n",
    "print(f\"\\n=== å½“å‰å·¥ä½œç›®å½• ===\")\n",
    "print(f\"å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"ä¸¤è€…æ˜¯å¦ç›¸åŒ: {os.getcwd() == BASE_DIR}\")\n",
    "\n",
    "# ç„¶åç»§ç»­åŸæ¥çš„ä»£ç ï¼Œä½†ä½¿ç”¨å°å†™æ¨¡å¼\n",
    "csv_files = sorted(glob(os.path.join(FIRE_DIR, 'modis_20*_china.csv')))\n",
    "print(f\"\\næœ€ç»ˆåŒ¹é…åˆ°çš„æ–‡ä»¶æ•°é‡: {len(csv_files)}\")\n",
    "\n",
    "if len(csv_files) == 0:\n",
    "    print(\"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°åŒ¹é…çš„ç«ç‚¹CSVæ–‡ä»¶\")\n",
    "    # è¿™é‡Œå¯ä»¥é€‰æ‹©é€€å‡ºæˆ–è€…æŠ›å‡ºå¼‚å¸¸\n",
    "    raise FileNotFoundError(\"æœªæ‰¾åˆ°ç«ç‚¹CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶åå’Œè·¯å¾„\")\n",
    "else:\n",
    "    print(f'âœ… å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶ï¼š', [os.path.basename(f) for f in csv_files])\n",
    "print(f'å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶ï¼š', os.path.basename(csv_files[0]), '...')\n",
    "\n",
    "# æœŸæœ›åˆ—ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨è·³è¿‡ï¼‰\n",
    "desired_cols = [\n",
    "    'latitude','longitude','brightness','scan','track','acq_date','acq_time',\n",
    "    'satellite','instrument','confidence','version','bright_t31','frp','daynight','type'\n",
    "]\n",
    "\n",
    "# æŒ‡å®šåˆ—ç±»å‹ï¼ˆä»…å¯¹å­˜åœ¨çš„åˆ—ç”Ÿæ•ˆï¼‰ï¼Œå‡å°‘å†…å­˜å ç”¨\n",
    "DTYPES = {\n",
    "    'latitude': 'float32', 'longitude': 'float32',\n",
    "    'brightness': 'float32', 'scan': 'float32', 'track': 'float32',\n",
    "    'acq_time': 'int32', 'confidence': 'float32', 'version': 'string',\n",
    "    'bright_t31': 'float32', 'frp': 'float32', 'daynight': 'string', 'type': 'float32'\n",
    "}\n",
    "\n",
    "# æ¢æµ‹é¦–ä¸ªæ–‡ä»¶ä¸­å¯ç”¨åˆ—\n",
    "first_cols = pd.read_csv(csv_files[0], nrows=0).columns.str.lower().tolist()\n",
    "# æœ‰äº›æ•°æ®åˆ—åå¯èƒ½ä¸ºå¤§å†™ï¼Œå°†æ‰€æœ‰åˆ—åç»Ÿä¸€ä¸ºå°å†™åè¿›è¡ŒåŒ¹é…\n",
    "def read_with_lower_cols(path, **kwargs):\n",
    "    df0 = pd.read_csv(path, **kwargs)\n",
    "    df0.columns = df0.columns.str.lower()\n",
    "    return df0\n",
    "\n",
    "available = [c for c in desired_cols if c in first_cols]\n",
    "parse_dates = ['acq_date'] if 'acq_date' in available else []\n",
    "use_dtypes = {k: v for k, v in DTYPES.items() if k in available}\n",
    "\n",
    "frames = []\n",
    "for f in csv_files:\n",
    "    df = read_with_lower_cols(\n",
    "        f,\n",
    "        dtype=use_dtypes if len(use_dtypes)>0 else None,\n",
    "        usecols=available if len(available)>0 else None,\n",
    "        parse_dates=parse_dates if len(parse_dates)>0 else None\n",
    "    )\n",
    "    frames.append(df)\n",
    "\n",
    "fires = pd.concat(frames, ignore_index=True)\n",
    "# åŸºç¡€æ¸…æ´—\n",
    "# ç»Ÿä¸€å…³é”®åˆ—å­˜åœ¨æ€§\n",
    "for col in ['latitude','longitude']:\n",
    "    assert col in fires.columns, f'å…³é”®åˆ—ç¼ºå¤±: {col}'\n",
    "\n",
    "if 'acq_date' in fires.columns and not np.issubdtype(fires['acq_date'].dtype, np.datetime64):\n",
    "    # è‹¥æœªè§£æä¸ºæ—¥æœŸ\n",
    "    fires['acq_date'] = pd.to_datetime(fires['acq_date'], errors='coerce')\n",
    "\n",
    "fires = fires.dropna(subset=['latitude','longitude','acq_date'])\n",
    "fires['year'] = fires['acq_date'].dt.year.astype('int16')\n",
    "fires['month'] = fires['acq_date'].dt.month.astype('int8')\n",
    "\n",
    "print('åˆå¹¶åè®°å½•æ•°:', len(fires))\n",
    "fires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç½®ä¿¡åº¦é˜ˆå€¼ä¸åœ°ç†ç‚¹æ„å»º\n",
    "CONF_THRESHOLD = 30  # å¯è°ƒæ•´ï¼šä»…ä¿ç•™ç½®ä¿¡åº¦>=30çš„ç«ç‚¹\n",
    "fires_filt = fires.loc[fires['confidence'] >= CONF_THRESHOLD].copy()\n",
    "\n",
    "# æ„å»º GeoDataFrameï¼ˆWGS84ï¼‰\n",
    "geometry = [Point(xy) for xy in zip(fires_filt['longitude'], fires_filt['latitude'])]\n",
    "fires_gdf = gpd.GeoDataFrame(fires_filt, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "print('è¿‡æ»¤åè®°å½•æ•°:', len(fires_gdf))\n",
    "fires_gdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72512fba",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒä»»åŠ¡ 1ï¼šæ„å»ºç«ç‚¹åœ°ç†æ•°æ®é›†\n",
    "å·²æˆåŠŸæ„å»ºåŸºäº WGS84 (EPSG:4326) çš„ç«ç‚¹åœ°ç†æ•°æ®é›†ã€‚ç»çº¬åº¦åæ ‡è½¬æ¢ä¸º Shapely Point å¯¹è±¡ï¼Œç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤åä¿ç•™ 994,029 ä¸ªæœ‰æ•ˆç«ç‚¹ï¼Œç¡®ä¿æ•°æ®è´¨é‡ä¸åœ°ç†å‡†ç¡®æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95150026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–å¿çº§è¾¹ç•Œå¹¶æ£€æŸ¥CRS\n",
    "counties = gpd.read_file(COUNTY_SHP)\n",
    "print('å¿ç•Œæ¡ç›®æ•°:', len(counties))\n",
    "print('å¿ç•Œåˆ—åç¤ºä¾‹:', list(counties.columns)[:10])\n",
    "print('å¿ç•ŒCRS:', counties.crs)\n",
    "\n",
    "# ç»Ÿä¸€åˆ° WGS84 ä»¥ä¾¿ç©ºé—´è¿æ¥ï¼ˆç‚¹åœ¨4326ï¼‰\n",
    "if counties.crs is None:\n",
    "    # è‹¥æ— CRSï¼ŒæŒ‰æ•°æ®æ¥æºå¸¸è§åæ ‡å‡å®šä¸º WGS84ï¼ˆå¦‚æœ‰å…ƒæ•°æ®è¯·æ›´æ­£ï¼‰\n",
    "    counties = counties.set_crs('EPSG:4326')\n",
    "elif counties.crs.to_string().lower() != 'epsg:4326':\n",
    "    counties = counties.to_crs('EPSG:4326')\n",
    "\n",
    "counties.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç©ºé—´è¿æ¥ï¼šå°†ç«ç‚¹å½’å±åˆ°å¿åŸŸ\n",
    "fires_joined = gpd.sjoin(fires_gdf, counties, how='inner', predicate='within')\n",
    "print('è¿æ¥åè®°å½•æ•°:', len(fires_joined))\n",
    "\n",
    "# å°è¯•è¯†åˆ«å¿åå­—æ®µï¼ˆæ ¹æ®å¸¸è§å­—æ®µåçŒœæµ‹ï¼Œå«ä¸­æ–‡åˆ—åï¼‰\n",
    "possible_name_cols = ['åœ°å', 'NAME', 'NAME_2', 'name', 'county', 'County', 'COUNTY', 'ADM2_CN', 'ADM2_EN']\n",
    "name_col = None\n",
    "for c in possible_name_cols:\n",
    "    if c in fires_joined.columns:\n",
    "        name_col = c\n",
    "        break\n",
    "\n",
    "if name_col is None:\n",
    "    # è‹¥æœªçŸ¥å¿ååˆ—ï¼Œåˆ™ä½¿ç”¨ç´¢å¼•ç¼–ç \n",
    "    fires_joined['county_name'] = fires_joined.index_right.astype(str)\n",
    "    name_col = 'county_name'\n",
    "\n",
    "print('ä½¿ç”¨å¿åå­—æ®µ:', name_col)\n",
    "\n",
    "fires_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00785bd7",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒä»»åŠ¡ 2ï¼šä¸å¿çº§è¾¹ç•Œè¿›è¡Œç©ºé—´å åŠ \n",
    "å·²å®Œæˆç«ç‚¹ä¸ 2,860 ä¸ªä¸­å›½å¿ç•Œè¾¹ç•Œçš„ç©ºé—´å åŠ ã€‚ä½¿ç”¨ GeoPandas sjoin (predicate='within')ï¼ŒæˆåŠŸå½’å± 991,951 ä¸ªç«ç‚¹è‡³å¿åŸŸï¼Œè‡ªåŠ¨è¯†åˆ«å¿ååˆ— ('åœ°å')ï¼Œç¡®ä¿ç©ºé—´åŒ¹é…å‡†ç¡®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿éšœåˆ†ç»„å­—æ®µå­˜åœ¨ï¼šè‹¥ç¼ºå¤±åˆ™ä»æ—¥æœŸé‡å»º\n",
    "needed_cols = []\n",
    "if 'year' not in fires_joined.columns and 'acq_date' in fires_joined.columns:\n",
    "    fires_joined['year'] = pd.to_datetime(fires_joined['acq_date'], errors='coerce').dt.year.astype('Int16')\n",
    "    needed_cols.append('year')\n",
    "if 'month' not in fires_joined.columns and 'acq_date' in fires_joined.columns:\n",
    "    fires_joined['month'] = pd.to_datetime(fires_joined['acq_date'], errors='coerce').dt.month.astype('Int8')\n",
    "    needed_cols.append('month')\n",
    "print('å·²è¡¥å……åˆ—:', needed_cols)\n",
    "list(fires_joined.columns)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿åŸŸ-å¹´åº¦ ä¸ å¿åŸŸ-å¹´æœˆ èšåˆï¼ˆå…¼å®¹ year/year_left ç­‰åˆ—åï¼‰\n",
    "_year_col = 'year' if 'year' in fires_joined.columns else ('year_left' if 'year_left' in fires_joined.columns else None)\n",
    "_month_col = 'month' if 'month' in fires_joined.columns else ('month_left' if 'month_left' in fires_joined.columns else None)\n",
    "\n",
    "if _year_col is None:\n",
    "    raise KeyError('æœªæ‰¾åˆ°å¹´ä»½åˆ—ï¼šæœŸæœ› year æˆ– year_left')\n",
    "if _month_col is None:\n",
    "    raise KeyError('æœªæ‰¾åˆ°æœˆä»½åˆ—ï¼šæœŸæœ› month æˆ– month_left')\n",
    "\n",
    "agg_dict = {'fire_count': ('frp','size')}\n",
    "if 'frp' in fires_joined.columns:\n",
    "    agg_dict.update({\n",
    "        'frp_sum': ('frp','sum'),\n",
    "        'frp_mean': ('frp','mean')\n",
    "    })\n",
    "\n",
    "agg_year = (fires_joined\n",
    "            .groupby([name_col, _year_col])\n",
    "            .agg(**agg_dict)\n",
    "            .reset_index()\n",
    "            .rename(columns={_year_col: 'year'}))\n",
    "\n",
    "agg_yearmonth = (fires_joined\n",
    "                 .groupby([name_col, _year_col, _month_col])\n",
    "                 .agg(**agg_dict)\n",
    "                 .reset_index()\n",
    "                 .rename(columns={_year_col: 'year', _month_col: 'month'}))\n",
    "\n",
    "print('å¹´åº¦èšåˆè¡Œæ•°:', len(agg_year))\n",
    "print('å¹´æœˆèšåˆè¡Œæ•°:', len(agg_yearmonth))\n",
    "agg_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d264c6",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒä»»åŠ¡ 3ï¼šç»Ÿè®¡å¿åŸŸ-å¹´åº¦/å¿åŸŸ-å¹´æœˆç«ç‚¹æ•°é‡ä¸ FRP æŒ‡æ ‡\n",
    "å·²ç»Ÿè®¡å¿åŸŸå¹´åº¦èšåˆ (25,424 è¡Œ) ä¸å¹´æœˆèšåˆ (133,392 è¡Œ)ã€‚åŒ…æ‹¬ç«ç‚¹æ•°é‡ã€FRP æ€»å’Œä¸å‡å€¼ï¼ŒæŒ‰å¿-å¹´/å¿-å¹´æœˆåˆ†ç»„ï¼Œç¡®ä¿æ—¶ç©ºç²’åº¦ç»Ÿè®¡å®Œæ•´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89892d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—å¿åŸŸé¢ç§¯ä¸ç«ç‚¹å¯†åº¦ï¼ˆæ¯åƒå¹³æ–¹å…¬é‡Œï¼‰\n",
    "# ä½¿ç”¨ç­‰é¢ç§¯æŠ•å½±ï¼ˆWorld Equal Area EPSG:6933ï¼‰\n",
    "counties_eq = counties.to_crs('EPSG:6933')\n",
    "counties_eq['area_km2'] = counties_eq.geometry.area / 1e6\n",
    "\n",
    "# æ„å»ºä¸ name_col å¯¹åº”çš„é¢ç§¯è¡¨\n",
    "if 'name_col' not in globals():\n",
    "    raise RuntimeError('name_col æœªå®šä¹‰ï¼Œè¯·å…ˆè¿è¡Œç©ºé—´è¿æ¥å•å…ƒæ ¼ã€‚')\n",
    "\n",
    "if name_col in counties.columns:\n",
    "    area_df = counties_eq[[name_col]].copy()\n",
    "    area_df['area_km2'] = counties_eq['area_km2'].values\n",
    "else:\n",
    "    # ä½¿ç”¨ç´¢å¼•ä½œä¸ºæ ‡è¯†ï¼Œä¸ fires_joined ä¸­çš„ index_right â†’ county_name å¯¹åº”\n",
    "    tmp = counties_eq.reset_index().rename(columns={'index': name_col})\n",
    "    area_df = tmp[[name_col, 'area_km2']].copy()\n",
    "\n",
    "# å°†å¹´åº¦èšåˆå¹¶å›é¢ç§¯\n",
    "agg_year_geo = pd.merge(\n",
    "    agg_year,\n",
    "    area_df,\n",
    "    on=name_col, how='left'\n",
    ")\n",
    "agg_year_geo['fire_density_per_1000km2'] = agg_year_geo['fire_count'] / (agg_year_geo['area_km2'] / 1000)\n",
    "\n",
    "agg_year_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cfa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å‡ºç»“æœ\n",
    "agg_year.to_csv(os.path.join(OUT_DIR, 'county_year_fire_stats.csv'), index=False)\n",
    "agg_yearmonth.to_csv(os.path.join(OUT_DIR, 'county_year_month_fire_stats.csv'), index=False)\n",
    "\n",
    "# å¯é€‰ï¼šå¯¼å‡ºå¿ç•ŒGeoJSONï¼ˆä¾¿äºå¯è§†åŒ–ä½¿ç”¨ï¼‰\n",
    "counties.to_file(os.path.join(OUT_DIR, 'china_counties.geojson'), driver='GeoJSON')\n",
    "\n",
    "print('å·²å¯¼å‡ºåˆ°:', OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b56338d",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒä»»åŠ¡ 5ï¼šäº§å‡ºåˆ†æå›¾è¡¨ä¸ç»“æœè¡¨æ ¼ï¼ˆCSV/GeoJSONï¼‰ï¼Œç¡®ä¿å¯å¤ç°\n",
    "å·²å¯¼å‡ºå¹´åº¦ç»Ÿè®¡ CSV (county_year_fire_stats.csv)ã€å¹´æœˆç»Ÿè®¡ CSV (county_year_month_fire_stats.csv) åŠå¿ç•Œ GeoJSON (china_counties.geojson)ã€‚å›¾è¡¨åŒ…æ‹¬è¶‹åŠ¿å›¾ã€Top10 å¯¹æ¯”ã€å­£èŠ‚æ€§å›¾åŠå¯†åº¦åˆ†çº§åœ°å›¾ï¼Œç¡®ä¿ç»“æœå¯å¤ç°ä¸è¿½æº¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– 1ï¼šå…¨å›½å¹´åº¦ç«ç‚¹è¶‹åŠ¿\n",
    "plt.figure(figsize=(9,4))\n",
    "fires_year = fires_gdf.groupby('year').size().reset_index(name='count')\n",
    "sns.lineplot(data=fires_year, x='year', y='count', marker='o')\n",
    "plt.title('å…¨å›½å¹´åº¦ç«ç‚¹æ•°é‡ï¼ˆç½®ä¿¡åº¦â‰¥%dï¼‰' % CONF_THRESHOLD)\n",
    "plt.xlabel('å¹´ä»½')\n",
    "plt.ylabel('ç«ç‚¹æ•°é‡')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012e03a",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒä»»åŠ¡ 4ï¼šè¿›è¡Œå…¨å›½å¹´åº¦è¶‹åŠ¿ã€å­£èŠ‚æ€§ä¸â€œé«˜ç«ç‚¹å¿â€å¯¹æ¯”\n",
    "å·²ç”Ÿæˆå…¨å›½å¹´åº¦ç«ç‚¹è¶‹åŠ¿çº¿å›¾ (2010-2019)ï¼Œæ˜¾ç¤ºæ€»ä½“æ³¢åŠ¨ï¼›æœˆåº¦å­£èŠ‚æ€§æ¡å½¢å›¾ï¼Œçªå‡ºæ˜¥å­£ (3-5æœˆ) é«˜å‘ï¼›Top10 é«˜ç«ç‚¹å¿æ¨ªå‘æ¡å½¢å›¾ï¼ŒæŒ‰ç´¯è®¡ç«ç‚¹æ’åºï¼Œè¯†åˆ«çƒ­ç‚¹åŒºåŸŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– 2ï¼šTop10 å¿ï¼ˆæŒ‰ç´¯è®¡ç«ç‚¹ï¼‰\n",
    "plt.figure(figsize=(10,5))\n",
    "rank = (agg_year.groupby(name_col)['fire_count'].sum()\n",
    "         .sort_values(ascending=False).head(10)[::-1])\n",
    "sns.barplot(x=rank.values, y=rank.index, orient='h', color='#d95f02')\n",
    "plt.title('ç´¯è®¡ç«ç‚¹ Top10 å¿ï¼ˆ2010â€“2019ï¼Œç½®ä¿¡åº¦â‰¥%dï¼‰' % CONF_THRESHOLD)\n",
    "plt.xlabel('ç«ç‚¹æ•°é‡')\n",
    "plt.ylabel('å¿')\n",
    "plt.grid(axis='x', alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– 3ï¼šå­£èŠ‚æ€§ï¼ˆæŒ‰æœˆä»½æ±‡æ€»ï¼‰\n",
    "plt.figure(figsize=(9,4))\n",
    "fires_month = fires_gdf.groupby('month').size().reset_index(name='count')\n",
    "sns.barplot(data=fires_month, x='month', y='count', color='#1b9e77')\n",
    "plt.title('å…¨å›½æœˆåº¦ç«ç‚¹å­£èŠ‚æ€§ï¼ˆ2010â€“2019ï¼Œç½®ä¿¡åº¦â‰¥%dï¼‰' % CONF_THRESHOLD)\n",
    "plt.xlabel('æœˆä»½')\n",
    "plt.ylabel('ç«ç‚¹æ•°é‡')\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e27fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ°å›¾ï¼šé€‰æ‹©æŸå¹´å±•ç¤ºå¿åŸŸç«ç‚¹å¯†åº¦ï¼ˆåˆ†çº§è®¾è‰²ï¼‰\n",
    "YEAR_TO_MAP = int(fires_gdf['year'].median())  # é»˜è®¤é€‰ä¸­ä½æ•°å¹´ä»½\n",
    "\n",
    "# å°†å¯†åº¦æŒ‡æ ‡ä¸å¿ç•Œåˆå¹¶æˆGeoDataFrame\n",
    "agg_y = agg_year_geo[agg_year_geo['year'] == YEAR_TO_MAP].copy()\n",
    "# ä¿ç•™å¿ç•Œå‡ ä½•\n",
    "if name_col not in counties.columns:\n",
    "    counties_plot = counties.rename(columns={counties.columns[0]: name_col})\n",
    "else:\n",
    "    counties_plot = counties[[name_col, 'geometry']].copy()\n",
    "\n",
    "choropleth = counties_plot.merge(agg_y[[name_col, 'fire_density_per_1000km2']], on=name_col, how='left')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "choropleth.plot(column='fire_density_per_1000km2', ax=ax, cmap='OrRd', legend=True,\n",
    "                legend_kwds={'label': 'ç«ç‚¹å¯†åº¦ï¼ˆæ¬¡/åƒkmÂ²ï¼‰', 'shrink': 0.6},\n",
    "                missing_kwds={'color': 'lightgrey', 'label': 'æ— è®°å½•'})\n",
    "ax.set_title(f'å¿åŸŸç«ç‚¹å¯†åº¦ | {YEAR_TO_MAP} å¹´ï¼ˆç½®ä¿¡åº¦â‰¥{CONF_THRESHOLD}ï¼‰')\n",
    "ax.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
