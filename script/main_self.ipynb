{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e9ab2",
   "metadata": {},
   "source": [
    "**项目：我国研究区域火灾活动的主导时空模式与季节性**\n",
    "\n",
    "本节目标：\n",
    "- 明确研究数据与处理流程。\n",
    "- 构建从原始卫星火点数据到时空统计与可视化的分析管线。\n",
    "- 产出两类结论：\n",
    "  1) 全部火灾事件的季节性（按月/季节的时间分布）。\n",
    "  2) 地理分布（空间聚集、县域尺度分布）。\n",
    "\n",
    "数据来源与位置：\n",
    "- 原始数据在 `raw_data/` 下：\n",
    "  - 卫星火点数据：`raw_data/satellite_fire_data/modis_*.csv`（2010–2019）。\n",
    "  - 中国县级边界：`raw_data/chn_county/chn_county.shp`。\n",
    "\n",
    "方法概述：\n",
    "- 读取并合并 2010–2019 年 MODIS 火点数据；标准化经纬度、时间字段，生成 GeoDataFrame。\n",
    "- 计算月度与季节聚合，绘制折线图与年×月热力图，刻画季节性。\n",
    "- 读取县界矢量，做空间连接，统计县域总火点数与年尺度火点数，绘制县域火点分布图。\n",
    "- 将关键汇总表导出至 `results/` 目录。\n",
    "\n",
    "注意：\n",
    "- 代码对常见列名做了鲁棒匹配（latitude/lat、longitude/lon、acq_date/date 等）。\n",
    "- 若 shapefile 或某些年份数据缺失，流程会给出提示但尽量继续运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务1输出目录改写（将结果写入 results/task1）\n",
    "from pathlib import Path\n",
    "import os\n",
    "try:\n",
    "    ROOT = Path.cwd()\n",
    "    RESULTS_TASK1 = ROOT/'results'/'task1'\n",
    "    RESULTS_TASK1.mkdir(parents=True, exist_ok=True)\n",
    "    # 若已有全局 RESULTS_DIR（任务1可能使用它保存），则重定向到 task1\n",
    "    if 'RESULTS_DIR' in globals():\n",
    "        RESULTS_DIR = RESULTS_TASK1\n",
    "    else:\n",
    "        RESULTS_DIR = RESULTS_TASK1\n",
    "    print('Task1 输出目录:', RESULTS_DIR)\n",
    "except Exception as e:\n",
    "    print('Task1 输出目录改写失败:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础库导入与全局设置\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 统一绘图风格\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 字体设置：自动使用系统中可用的中文字体\n",
    "from matplotlib import font_manager\n",
    "def set_chinese_font(preferred=('Microsoft YaHei','SimHei','SimSun','Noto Sans CJK SC','Source Han Sans SC','WenQuanYi Zen Hei')):\n",
    "    available = set(f.name for f in font_manager.fontManager.ttflist)\n",
    "    for name in preferred:\n",
    "        if name in available:\n",
    "            plt.rcParams['font.sans-serif'] = [name]\n",
    "            print('使用中文字体:', name)\n",
    "            return name\n",
    "    # 兜底：保留默认 sans-serif，并提示\n",
    "    plt.rcParams['font.sans-serif'] = plt.rcParams.get('font.sans-serif', ['DejaVu Sans'])\n",
    "    print('未检测到常见中文字体，可能导致中文无法显示。请在系统安装如 SimHei 或 Microsoft YaHei。')\n",
    "set_chinese_font()\n",
    "\n",
    "print(\"Libraries imported and font configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路径配置与辅助函数\n",
    "# 自动探测仓库根目录（向上查找包含 raw_data 的目录）\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_repo_root(start: Path = Path.cwd()) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'raw_data').exists():\n",
    "            return p\n",
    "    # 兜底：若当前在 script/ 下\n",
    "    return start.parent if start.name == 'script' else start\n",
    "\n",
    "REPO_ROOT = detect_repo_root()\n",
    "RAW_DIR = REPO_ROOT / 'raw_data'\n",
    "FIRE_DIR = RAW_DIR / 'satellite_fire_data'\n",
    "COUNTY_SHP = RAW_DIR / 'chn_county' / 'chn_county.shp'\n",
    "RESULTS_DIR = REPO_ROOT / 'results'\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Repo root:', REPO_ROOT)\n",
    "print('Fire data dir exists:', FIRE_DIR.exists())\n",
    "print('County shp exists:', COUNTY_SHP.exists())\n",
    "print('Results dir:', RESULTS_DIR)\n",
    "\n",
    "# 将月份映射到季节（可根据研究需要调整）\n",
    "MONTH2SEASON = {\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "     3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "     6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "     9: 'Autumn', 10: 'Autumn', 11: 'Autumn'\n",
    "}\n",
    "\n",
    "def find_column(cols, candidates):\n",
    "    \"\"\"在列名中查找第一个匹配项（大小写不敏感）。\n",
    "    candidates: 如 ['latitude','lat']\n",
    "    返回匹配到的列名或 None。\n",
    "    \"\"\"\n",
    "    for cand in candidates:\n",
    "        for col in cols:\n",
    "            if col.lower() == cand.lower():\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "def build_datetime(df):\n",
    "    \"\"\"从常见字段构造 datetime 列，并补充 year/month/day/season。\"\"\"\n",
    "    import pandas as pd\n",
    "    # 常见字段：acq_date(YYYY-MM-DD)、acq_time(HHMM)\n",
    "    date_col = find_column(df.columns, ['acq_date', 'date', 'acq-date'])\n",
    "    time_col = find_column(df.columns, ['acq_time', 'time', 'acq-time'])\n",
    "    dt = None\n",
    "    if date_col is not None and time_col is not None:\n",
    "        # 将 HHMM 转换为 HH:MM\n",
    "        def _fmt_time(t):\n",
    "            try:\n",
    "                s = str(int(t)).zfill(4)\n",
    "                return f\"{s[:2]}:{s[2:]}\"\n",
    "            except Exception:\n",
    "                return None\n",
    "        times = df[time_col].apply(_fmt_time)\n",
    "        dt = pd.to_datetime(df[date_col].astype(str) + ' ' + times.astype(str), errors='coerce')\n",
    "    elif date_col is not None:\n",
    "        dt = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    else:\n",
    "        # 有的产品用 'timestamp'\n",
    "        ts_col = find_column(df.columns, ['timestamp'])\n",
    "        if ts_col is not None:\n",
    "            dt = pd.to_datetime(df[ts_col], errors='coerce')\n",
    "    if dt is None:\n",
    "        raise ValueError('未能识别日期/时间列，请检查原始 CSV 列名。')\n",
    "\n",
    "    df['datetime'] = dt\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['season'] = df['month'].map(MONTH2SEASON)\n",
    "    return df\n",
    "\n",
    "def to_geodf(df):\n",
    "    \"\"\"将 DataFrame 转为 WGS84 的 GeoDataFrame。\"\"\"\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    lon_col = find_column(df.columns, ['longitude', 'lon', 'long'])\n",
    "    lat_col = find_column(df.columns, ['latitude', 'lat'])\n",
    "    if lon_col is None or lat_col is None:\n",
    "        raise ValueError('未找到经纬度列（longitude/latitude 或 lon/lat）。')\n",
    "    geometry = [Point(xy) for xy in zip(df[lon_col].astype(float), df[lat_col].astype(float))]\n",
    "    gdf = gpd.GeoDataFrame(df.copy(), geometry=geometry, crs='EPSG:4326')\n",
    "    return gdf\n",
    "\n",
    "print('Helpers ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取并合并 2010–2019 年卫星火点数据\n",
    "from glob import glob\n",
    "\n",
    "csv_paths = sorted(glob(str(FIRE_DIR / 'modis_*_china.csv')))\n",
    "if not csv_paths:\n",
    "    print('未找到 CSV：', FIRE_DIR)\n",
    "else:\n",
    "    print(f'发现 {len(csv_paths)} 个年份文件')\n",
    "\n",
    "frames = []\n",
    "for p in csv_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        # 构造时间字段\n",
    "        df = build_datetime(df)\n",
    "        # 限定合理经纬度范围（粗滤除异常值）\n",
    "        lon_col = find_column(df.columns, ['longitude', 'lon', 'long'])\n",
    "        lat_col = find_column(df.columns, ['latitude', 'lat'])\n",
    "        if lon_col and lat_col:\n",
    "            df = df[(df[lon_col].between(70, 140)) & (df[lat_col].between(15, 55))]\n",
    "        # 添加年份来源（从文件名解析）\n",
    "        # 文件命名形如 modis_2010_china.csv\n",
    "        try:\n",
    "            year_in_name = int(Path(p).stem.split('_')[1])\n",
    "            df['year_from_fname'] = year_in_name\n",
    "        except Exception:\n",
    "            df['year_from_fname'] = df['year']\n",
    "        frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f'读取失败 {p}: {e}')\n",
    "\n",
    "fire_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "print('合并后记录数:', len(fire_df))\n",
    "\n",
    "# 转为 GeoDataFrame\n",
    "if not fire_df.empty:\n",
    "    fire_gdf = to_geodf(fire_df)\n",
    "    # 确保 CRS 为 WGS84\n",
    "    fire_gdf = fire_gdf.set_crs('EPSG:4326', allow_override=True)\n",
    "    display(fire_gdf.head(3))\n",
    "else:\n",
    "    fire_gdf = gpd.GeoDataFrame(columns=['datetime','year','month','season','geometry'], geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "print('GeoDataFrame ready:', len(fire_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据概览与完整性检查\n",
    "if len(fire_gdf) == 0:\n",
    "    print('没有有效火点记录，后续单元可能无法绘图。请检查 raw_data/satellite_fire_data 是否存在并包含 CSV。')\n",
    "else:\n",
    "    # 时间范围\n",
    "    tmin, tmax = fire_gdf['datetime'].min(), fire_gdf['datetime'].max()\n",
    "    print(f\"时间范围: {tmin} — {tmax}\")\n",
    "    print('年份分布:')\n",
    "    display(fire_gdf['year'].value_counts().sort_index())\n",
    "\n",
    "    # 缺失情况\n",
    "    missing = fire_gdf[['datetime','year','month','season','geometry']].isna().mean().round(4)\n",
    "    print('关键字段缺失率:')\n",
    "    display(missing)\n",
    "\n",
    "    # 简要统计\n",
    "    print('火点总数:', len(fire_gdf))\n",
    "    print('唯一日期数:', fire_gdf['date'].nunique())\n",
    "\n",
    "    # 示例前几行\n",
    "    display(fire_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb6635",
   "metadata": {},
   "source": [
    "# 季节性与时间分布：思路说明\n",
    "本节从时间维度刻画火灾活动的主导模式：\n",
    "- 按月聚合，观察跨年总体的月度强度变化（折线图）。\n",
    "- 计算“年×月”的二维分布热力图，看每年内的季节高峰是否一致或有迁移。\n",
    "- 按季节（春夏秋冬）汇总并比较总量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 月度聚合与折线图\n",
    "if len(fire_gdf) > 0:\n",
    "    monthly = fire_gdf.groupby('month').size().rename('count').reset_index()\n",
    "    monthly = monthly.sort_values('month')\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.lineplot(data=monthly, x='month', y='count', marker='o')\n",
    "    plt.title('全部年份合并的月度火点数分布')\n",
    "    plt.xlabel('月份')\n",
    "    plt.ylabel('火点数')\n",
    "    plt.xticks(range(1,13))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 保存 CSV 与图\n",
    "    monthly_out = RESULTS_DIR / 'all_years_monthly_fire_counts.csv'\n",
    "    monthly.to_csv(monthly_out, index=False)\n",
    "    print('保存:', monthly_out)\n",
    "else:\n",
    "    print('无数据，跳过月度聚合。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年 × 月 热力图（观察年内季节峰值与跨年差异）\n",
    "if len(fire_gdf) > 0:\n",
    "    year_month = fire_gdf.groupby(['year','month']).size().rename('count').reset_index()\n",
    "    # 仅保留合理年份（从文件名或数据解析获得）\n",
    "    if 'year_from_fname' in fire_gdf.columns:\n",
    "        year_month = fire_gdf.groupby(['year_from_fname','month']).size().rename('count').reset_index()\n",
    "        year_month = year_month.rename(columns={'year_from_fname':'year'})\n",
    "\n",
    "    pivot = year_month.pivot(index='year', columns='month', values='count').fillna(0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(pivot, cmap='YlOrRd', linewidths=0.3, linecolor='white')\n",
    "    plt.title('年/月 火点数热力图')\n",
    "    plt.xlabel('月份')\n",
    "    plt.ylabel('年份')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 导出\n",
    "    ym_out = RESULTS_DIR / 'year_month_fire_counts.csv'\n",
    "    pivot.to_csv(ym_out)\n",
    "    print('保存:', ym_out)\n",
    "else:\n",
    "    print('无数据，跳过年/月热力图。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c521a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按季节汇总（春夏秋冬）\n",
    "if len(fire_gdf) > 0:\n",
    "    season_counts = fire_gdf.groupby('season').size().rename('count').reset_index()\n",
    "    order = ['Spring','Summer','Autumn','Winter']\n",
    "    season_counts['season'] = pd.Categorical(season_counts['season'], categories=order, ordered=True)\n",
    "    season_counts = season_counts.sort_values('season')\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(data=season_counts, x='season', y='count', palette='viridis')\n",
    "    plt.title('按季节汇总的火点数')\n",
    "    plt.xlabel('季节')\n",
    "    plt.ylabel('火点数')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    season_out = RESULTS_DIR / 'season_fire_counts.csv'\n",
    "    season_counts.to_csv(season_out, index=False)\n",
    "    print('保存:', season_out)\n",
    "else:\n",
    "    print('无数据，跳过季节汇总。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa28334",
   "metadata": {},
   "source": [
    "# 趋势分析与显著性检验：思路说明\n",
    "本节使用非参数 Mann–Kendall 检验与 Sen’s slope 估计：\n",
    "- 年度总量序列（2010–2019）检验整体趋势及显著性，并输出结果与趋势图。\n",
    "- 按月份（1–12）构造“逐年同月火点数”序列，分别进行趋势检验，比较各月趋势差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年度总量的 Mann–Kendall 趋势检验与 Sen 斜率\n",
    "import math\n",
    "from itertools import combinations\n",
    "\n",
    "if len(fire_gdf) > 0:\n",
    "    # 选择年份字段\n",
    "    yr_col = 'year_from_fname' if 'year_from_fname' in fire_gdf.columns else 'year'\n",
    "    yearly = fire_gdf.groupby(yr_col).size().rename('count').reset_index().sort_values(yr_col)\n",
    "    years = yearly[yr_col].to_numpy()\n",
    "    x = years.astype(float)\n",
    "    y = yearly['count'].to_numpy(dtype=float)\n",
    "\n",
    "    def mk_test(series):\n",
    "        s = 0\n",
    "        n = len(series)\n",
    "        # S 统计量\n",
    "        for i in range(n-1):\n",
    "            diff = series[i+1:] - series[i]\n",
    "            s += np.sign(diff).sum()\n",
    "        # 方差（考虑 ties）\n",
    "        unique, counts = np.unique(series, return_counts=True)\n",
    "        tie_term = np.sum(counts*(counts-1)*(2*counts+5))\n",
    "        var_s = (n*(n-1)*(2*n+5) - tie_term) / 18.0\n",
    "        if s > 0:\n",
    "            z = (s - 1)/math.sqrt(var_s)\n",
    "        elif s < 0:\n",
    "            z = (s + 1)/math.sqrt(var_s)\n",
    "        else:\n",
    "            z = 0.0\n",
    "        # 正态分布双尾 p 值（使用 erf 近似）\n",
    "        p = 2*(1 - 0.5*(1 + math.erf(abs(z)/math.sqrt(2))))\n",
    "        return s, var_s, z, p\n",
    "\n",
    "    def sen_slope(t, series):\n",
    "        # t 为严格递增的时间（可用年份或索引）\n",
    "        slopes = []\n",
    "        n = len(series)\n",
    "        for i in range(n-1):\n",
    "            dy = series[i+1:] - series[i]\n",
    "            dt = t[i+1:] - t[i]\n",
    "            valid = dt != 0\n",
    "            if np.any(valid):\n",
    "                slopes.extend((dy[valid]/dt[valid]).tolist())\n",
    "        if len(slopes) == 0:\n",
    "            return 0.0\n",
    "        return float(np.median(slopes))\n",
    "\n",
    "    S, VAR_S, Z, P = mk_test(y)\n",
    "    slope = sen_slope(x, y)\n",
    "    # Theil–Sen 拦截：median(y - slope*x)\n",
    "    intercept = float(np.median(y - slope*x))\n",
    "\n",
    "    # 结果表\n",
    "    from pandas import DataFrame\n",
    "    res_df = DataFrame({\n",
    "        'metric': ['S','VAR_S','Z','p_value','Sen_slope','intercept','n'],\n",
    "        'value':  [S, VAR_S, Z, P, slope, intercept, len(y)]\n",
    "    })\n",
    "    out_csv = RESULTS_DIR / 'yearly_mk_trend_summary.csv'\n",
    "    res_df.to_csv(out_csv, index=False)\n",
    "    print('保存:', out_csv)\n",
    "\n",
    "    # 绘图：年度总量 + 趋势线\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.lineplot(x=years, y=y, marker='o', label='年度火点数')\n",
    "    plt.plot(years, intercept + slope*x, color='crimson', linewidth=2, label='趋势线 (Sen)')\n",
    "    title = f\"年度火点数趋势（M-K: Z={Z:.2f}, p={P:.3f}, slope={slope:.1f}/年）\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel('年份')\n",
    "    plt.ylabel('火点数')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_png = RESULTS_DIR / 'yearly_trend.png'\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.show()\n",
    "    print('保存:', out_png)\n",
    "else:\n",
    "    print('无数据，跳过年度趋势检验。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按月逐年序列的 Mann–Kendall 趋势检验\n",
    "import math\n",
    "\n",
    "if len(fire_gdf) > 0:\n",
    "    yr_col = 'year_from_fname' if 'year_from_fname' in fire_gdf.columns else 'year'\n",
    "    years_all = np.sort(fire_gdf[yr_col].dropna().unique())\n",
    "\n",
    "    def mk_test(series):\n",
    "        s = 0\n",
    "        n = len(series)\n",
    "        for i in range(n-1):\n",
    "            diff = series[i+1:] - series[i]\n",
    "            s += np.sign(diff).sum()\n",
    "        unique, counts = np.unique(series, return_counts=True)\n",
    "        tie_term = np.sum(counts*(counts-1)*(2*counts+5))\n",
    "        var_s = (n*(n-1)*(2*n+5) - tie_term) / 18.0\n",
    "        if s > 0:\n",
    "            z = (s - 1)/math.sqrt(var_s)\n",
    "        elif s < 0:\n",
    "            z = (s + 1)/math.sqrt(var_s)\n",
    "        else:\n",
    "            z = 0.0\n",
    "        p = 2*(1 - 0.5*(1 + math.erf(abs(z)/math.sqrt(2))))\n",
    "        return s, var_s, z, p\n",
    "\n",
    "    def sen_slope(t, series):\n",
    "        slopes = []\n",
    "        n = len(series)\n",
    "        for i in range(n-1):\n",
    "            dy = series[i+1:] - series[i]\n",
    "            dt = t[i+1:] - t[i]\n",
    "            valid = dt != 0\n",
    "            if np.any(valid):\n",
    "                slopes.extend((dy[valid]/dt[valid]).tolist())\n",
    "        if len(slopes) == 0:\n",
    "            return 0.0\n",
    "        return float(np.median(slopes))\n",
    "\n",
    "    rows = []\n",
    "    for m in range(1, 13):\n",
    "        sub = fire_gdf[fire_gdf['month'] == m]\n",
    "        counts = sub.groupby(yr_col).size().reindex(years_all, fill_value=0)\n",
    "        x = years_all.astype(float)\n",
    "        y = counts.to_numpy(dtype=float)\n",
    "        S, VAR_S, Z, P = mk_test(y)\n",
    "        slope = sen_slope(x, y)\n",
    "        rows.append({'month': m, 'S': S, 'VAR_S': VAR_S, 'Z': Z, 'p_value': P, 'Sen_slope': slope, 'n': len(y)})\n",
    "\n",
    "    month_mk = pd.DataFrame(rows)\n",
    "    out_csv = RESULTS_DIR / 'monthly_mk_trend_summary.csv'\n",
    "    month_mk.to_csv(out_csv, index=False)\n",
    "    print('保存:', out_csv)\n",
    "\n",
    "    # 可视化：按月 Sen 斜率柱状图\n",
    "    plt.figure(figsize=(9,4))\n",
    "    sns.barplot(data=month_mk, x='month', y='Sen_slope', palette='crest')\n",
    "    plt.axhline(0, color='gray', linewidth=1)\n",
    "    plt.title('逐月 Sen 斜率（年际趋势）')\n",
    "    plt.xlabel('月份')\n",
    "    plt.ylabel('Sen 斜率（火点/年）')\n",
    "    plt.tight_layout()\n",
    "    out_png = RESULTS_DIR / 'monthly_sen_slopes.png'\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.show()\n",
    "    print('保存:', out_png)\n",
    "else:\n",
    "    print('无数据，跳过逐月趋势检验。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2abea",
   "metadata": {},
   "source": [
    "# 地理分布：思路说明\n",
    "本节从空间维度刻画火灾活动的主导模式：\n",
    "- 将火点与县界做空间连接，得到县域尺度的火点统计（总量、分年）。\n",
    "- 绘制县域层面的连续色斑图（choropleth），展示空间分布格局。\n",
    "- 输出统计结果到 `results/` 供后续分析或图件制备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取县界并进行空间连接\n",
    "if len(fire_gdf) > 0 and COUNTY_SHP.exists():\n",
    "    counties = gpd.read_file(COUNTY_SHP)\n",
    "    # 标准化 CRS 为 WGS84（若非 WGS84，则投影到 EPSG:4326）\n",
    "    try:\n",
    "        if counties.crs is None:\n",
    "            # 常见中国县 shapefile 多为经纬度坐标\n",
    "            counties = counties.set_crs('EPSG:4326')\n",
    "        elif counties.crs.to_epsg() != 4326:\n",
    "            counties = counties.to_crs(4326)\n",
    "    except Exception:\n",
    "        counties = counties.to_crs(4326)\n",
    "\n",
    "    # 空间连接（点在面内）\n",
    "    join = gpd.sjoin(fire_gdf[['geometry','year']], counties, how='left', predicate='within')\n",
    "\n",
    "    # 解决 sjoin 造成的同名列冲突（例如 counties 也有 year 字段，会生成 year_left / year_right）\n",
    "    if 'year_left' in join.columns and 'year_right' in join.columns:\n",
    "        # 优先使用点表（fire_gdf）的年份信息（year_left）\n",
    "        join = join.rename(columns={'year_left': 'year'})\n",
    "        # 去掉面表的 year_right（若需要可改名保留）\n",
    "        join = join.drop(columns=['year_right'])\n",
    "    elif 'year_left' in join.columns:\n",
    "        join = join.rename(columns={'year_left': 'year'})\n",
    "    elif 'year_right' in join.columns and 'year' not in join.columns:\n",
    "        join = join.rename(columns={'year_right': 'year'})\n",
    "\n",
    "    # 尝试找到县级唯一标识字段（若未知，则使用索引）\n",
    "    candidate_keys = ['county_id','adcode','code','id','County_ID','COUNTY_ID']\n",
    "    key = None\n",
    "    for c in candidate_keys:\n",
    "        if c in join.columns:\n",
    "            key = c\n",
    "            break\n",
    "    if key is None:\n",
    "        # 若没有明确字段，恢复到 counties 的索引作为标识\n",
    "        counties = counties.reset_index().rename(columns={'index':'county_idx'})\n",
    "        join = gpd.sjoin(fire_gdf[['geometry','year']], counties, how='left', predicate='within')\n",
    "        # 再次处理重命名（同上）\n",
    "        if 'year_left' in join.columns and 'year_right' in join.columns:\n",
    "            join = join.rename(columns={'year_left': 'year'}).drop(columns=['year_right'])\n",
    "        elif 'year_left' in join.columns:\n",
    "            join = join.rename(columns={'year_left': 'year'})\n",
    "        elif 'year_right' in join.columns and 'year' not in join.columns:\n",
    "            join = join.rename(columns={'year_right': 'year'})\n",
    "        key = 'county_idx'\n",
    "\n",
    "    # 县域总量\n",
    "    county_counts = join.groupby(key).size().rename('fire_count').reset_index()\n",
    "    county_stats = counties.merge(county_counts, on=key, how='left')\n",
    "    county_stats['fire_count'] = county_stats['fire_count'].fillna(0).astype(int)\n",
    "\n",
    "    # 县域×年份（确保 join 中有 'year' 列）\n",
    "    if 'year' not in join.columns:\n",
    "        raise KeyError(\"'year' 列在空间连接结果中缺失，无法按年份统计。\")\n",
    "    county_year = join.groupby([key,'year']).size().rename('fire_count').reset_index()\n",
    "\n",
    "    # 导出\n",
    "    out_county_all = RESULTS_DIR / 'county_fire_counts.csv'\n",
    "    out_county_year = RESULTS_DIR / 'county_year_fire_counts.csv'\n",
    "    county_stats.drop(columns='geometry').to_csv(out_county_all, index=False)\n",
    "    county_year.to_csv(out_county_year, index=False)\n",
    "    print('保存:', out_county_all)\n",
    "    print('保存:', out_county_year)\n",
    "\n",
    "    # 绘制县域总量分布\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = counties.boundary.plot(edgecolor='lightgray', linewidth=0.3)\n",
    "    county_stats.plot(column='fire_count', ax=ax, legend=True, cmap='OrRd', linewidth=0, alpha=0.9)\n",
    "    plt.title('县域火点总量空间分布（2010–2019 合并）')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    if not COUNTY_SHP.exists():\n",
    "        print('未找到县界文件:', COUNTY_SHP)\n",
    "    else:\n",
    "        print('无火点数据，跳过空间连接。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ec763",
   "metadata": {},
   "source": [
    "# 周尺度与季节内模式：思路说明\n",
    "本节旨在超越“月度统计”，识别更细粒度的时间结构：\n",
    "- 周尺度（ISO 周）：\n",
    "  - 生成年×周热力图，观察热点周是否跨年一致；\n",
    "  - 计算跨年每周的均值/中位数/分位数，找出“热点周”。\n",
    "- 季节内（week-in-season）：\n",
    "  - 将每季按周序列化，比较季节内部的固定峰周或变动周；\n",
    "  - 识别各季的热点周并导出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f11acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 周尺度聚合与热点周识别（ISO Week）\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if len(fire_gdf) > 0:\n",
    "    # 计算 ISO 年/周（注意：返回的是 Int64 类型，需要转 int）\n",
    "    iso = fire_gdf['datetime'].dt.isocalendar()\n",
    "    fire_gdf['iso_year'] = iso['year'].astype(int)\n",
    "    fire_gdf['iso_week'] = iso['week'].astype(int)\n",
    "\n",
    "    weekly = fire_gdf.groupby(['iso_year','iso_week']).size().rename('count').reset_index()\n",
    "\n",
    "    # 年×周热力图\n",
    "    years = np.sort(weekly['iso_year'].unique())\n",
    "    weeks = np.arange(1, 54)  # 1..53 周\n",
    "    pivot = weekly.pivot(index='iso_year', columns='iso_week', values='count')\n",
    "    pivot = pivot.reindex(index=years, columns=weeks, fill_value=0)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(pivot, cmap='YlOrRd', linewidths=0.3, linecolor='white')\n",
    "    plt.title('年 × ISO周 火点数热力图')\n",
    "    plt.xlabel('ISO Week')\n",
    "    plt.ylabel('ISO Year')\n",
    "    plt.tight_layout()\n",
    "    heat_out = RESULTS_DIR / 'year_week_fire_counts_heatmap.png'\n",
    "    plt.savefig(heat_out, dpi=150)\n",
    "    plt.show()\n",
    "    print('保存:', heat_out)\n",
    "\n",
    "    # 导出年×周表\n",
    "    yw_out = RESULTS_DIR / 'year_week_fire_counts.csv'\n",
    "    pivot.to_csv(yw_out)\n",
    "    print('保存:', yw_out)\n",
    "\n",
    "    # 跨年每周统计（均值/中位数/分位）\n",
    "    stats = pd.DataFrame({\n",
    "        'week': weeks,\n",
    "        'mean': pivot.mean(axis=0).values,\n",
    "        'median': pivot.median(axis=0).values,\n",
    "        'p10': pivot.quantile(0.10, axis=0).values,\n",
    "        'p90': pivot.quantile(0.90, axis=0).values\n",
    "    })\n",
    "    stats_out = RESULTS_DIR / 'week_of_year_stats.csv'\n",
    "    stats.to_csv(stats_out, index=False)\n",
    "    print('保存:', stats_out)\n",
    "\n",
    "    # 识别热点周（两种方式：Top-N 与阈值）\n",
    "    top_n = 10\n",
    "    top_weeks = stats.sort_values('mean', ascending=False).head(top_n).copy()\n",
    "    # 阈值：均值 >= 均值均值 + 1 标准差\n",
    "    mu, sigma = stats['mean'].mean(), stats['mean'].std(ddof=0)\n",
    "    thr = mu + sigma\n",
    "    high_weeks = stats[stats['mean'] >= thr].copy()\n",
    "    hot = top_weeks.merge(high_weeks, on='week', how='outer', suffixes=('_top',''))\n",
    "    hot = hot.sort_values('mean', ascending=False).reset_index(drop=True)\n",
    "    hot_out = RESULTS_DIR / 'hot_weeks_summary.csv'\n",
    "    hot.to_csv(hot_out, index=False)\n",
    "    print('保存:', hot_out)\n",
    "\n",
    "    # 可视化：每周均值曲线 + p10-p90 区间\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.fill_between(stats['week'], stats['p10'], stats['p90'], color='#FDE725', alpha=0.25, label='P10–P90')\n",
    "    plt.plot(stats['week'], stats['mean'], color='#2C7FB8', linewidth=2, label='Mean')\n",
    "    plt.title('跨年每周火点数统计（均值与分位区间）')\n",
    "    plt.xlabel('ISO Week')\n",
    "    plt.ylabel('火点数')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    wcurve_out = RESULTS_DIR / 'week_of_year_curve.png'\n",
    "    plt.savefig(wcurve_out, dpi=150)\n",
    "    plt.show()\n",
    "    print('保存:', wcurve_out)\n",
    "else:\n",
    "    print('无数据，跳过周尺度分析。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 季节内（week-in-season）模式与热点周\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if len(fire_gdf) > 0:\n",
    "    # 计算 season_year：Winter 跨年，12月属于当年冬季，其余 1-2 月属于上一年冬季\n",
    "    def compute_season_year(row):\n",
    "        m = row['month']\n",
    "        y = row['year']\n",
    "        s = row['season']\n",
    "        if s == 'Winter':\n",
    "            if m == 12:\n",
    "                return y\n",
    "            else:  # 1,2 月\n",
    "                return y - 1\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "    fire_gdf['season_year'] = fire_gdf.apply(compute_season_year, axis=1)\n",
    "\n",
    "    # 计算季节起始日期\n",
    "    season_start_month = {'Spring':3,'Summer':6,'Autumn':9,'Winter':12}\n",
    "    def compute_season_start(row):\n",
    "        sy = int(row['season_year'])\n",
    "        mon = season_start_month.get(row['season'], 1)\n",
    "        return datetime(sy, mon, 1)\n",
    "\n",
    "    fire_gdf['season_start'] = fire_gdf.apply(compute_season_start, axis=1)\n",
    "\n",
    "    # 计算季节内的周序号（从1开始）\n",
    "    delta_days = (fire_gdf['datetime'] - fire_gdf['season_start']).dt.days\n",
    "    fire_gdf['week_in_season'] = (delta_days // 7).astype(int) + 1\n",
    "\n",
    "    # 聚合：按 season_year × season × week_in_season 统计\n",
    "    ssw = fire_gdf.groupby(['season_year','season','week_in_season']).size().rename('count').reset_index()\n",
    "\n",
    "    # 跨年统计：对每个 season 的同一 week_in_season 计算均值/分位\n",
    "    def season_stats(season_name):\n",
    "        sub = ssw[ssw['season'] == season_name]\n",
    "        if sub.empty:\n",
    "            return pd.DataFrame(columns=['season','week_in_season','mean','median','p10','p90'])\n",
    "        weeks = np.sort(sub['week_in_season'].unique())\n",
    "        # 构造 pivot: 行=season_year，列=week_in_season\n",
    "        pivot = sub.pivot(index='season_year', columns='week_in_season', values='count').reindex(columns=weeks).fillna(0)\n",
    "        return pd.DataFrame({\n",
    "            'season': season_name,\n",
    "            'week_in_season': weeks,\n",
    "            'mean': pivot.mean(axis=0).values,\n",
    "            'median': pivot.median(axis=0).values,\n",
    "            'p10': pivot.quantile(0.10, axis=0).values,\n",
    "            'p90': pivot.quantile(0.90, axis=0).values\n",
    "        })\n",
    "\n",
    "    seasons = ['Spring','Summer','Autumn','Winter']\n",
    "    stats_list = [season_stats(s) for s in seasons]\n",
    "    season_stats_df = pd.concat(stats_list, ignore_index=True) if stats_list else pd.DataFrame()\n",
    "\n",
    "    # 导出季节内统计\n",
    "    sstats_out = RESULTS_DIR / 'season_week_stats.csv'\n",
    "    season_stats_df.to_csv(sstats_out, index=False)\n",
    "    print('保存:', sstats_out)\n",
    "\n",
    "    # 识别各季热点周（按均值 Top-3 + 阈值）\n",
    "    hot_rows = []\n",
    "    for s in seasons:\n",
    "        sub = season_stats_df[season_stats_df['season'] == s]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        top3 = sub.sort_values('mean', ascending=False).head(3).copy()\n",
    "        mu, sigma = sub['mean'].mean(), sub['mean'].std(ddof=0)\n",
    "        thr = mu + sigma\n",
    "        over = sub[sub['mean'] >= thr].copy()\n",
    "        top3['flag'] = 'top3'\n",
    "        over['flag'] = '>=mean+1sd'\n",
    "        hot_rows.append(pd.concat([top3, over]).drop_duplicates(subset=['week_in_season']))\n",
    "    season_hot = pd.concat(hot_rows, ignore_index=True) if hot_rows else pd.DataFrame()\n",
    "    shot_out = RESULTS_DIR / 'season_hotspot_weeks.csv'\n",
    "    season_hot.to_csv(shot_out, index=False)\n",
    "    print('保存:', shot_out)\n",
    "\n",
    "    # 绘图：四季子图，均值线 + P10-P90 阴影\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=False, sharey=False)\n",
    "    axes = axes.ravel()\n",
    "    for i, s in enumerate(seasons):\n",
    "        ax = axes[i]\n",
    "        sub = season_stats_df[season_stats_df['season'] == s]\n",
    "        if sub.empty:\n",
    "            ax.set_title(f'{s}（无数据）')\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        ax.fill_between(sub['week_in_season'], sub['p10'], sub['p90'], color='#FDE725', alpha=0.25, label='P10–P90')\n",
    "        ax.plot(sub['week_in_season'], sub['mean'], color='#2C7FB8', linewidth=2, label='Mean')\n",
    "        ax.set_title(f'{s} 季节内周序列')\n",
    "        ax.set_xlabel('季节内周序号')\n",
    "        ax.set_ylabel('火点数')\n",
    "        ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    sw_plot = RESULTS_DIR / 'season_week_curves.png'\n",
    "    plt.savefig(sw_plot, dpi=150)\n",
    "    plt.show()\n",
    "    print('保存:', sw_plot)\n",
    "else:\n",
    "    print('无数据，跳过季节内周模式分析。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动生成简短摘要（可选）\n",
    "# 依据“热点周”与“季节内热点周”生成要点摘要，便于写作引用\n",
    "try:\n",
    "    lines = []\n",
    "    # 周尺度热点\n",
    "    hot_path = RESULTS_DIR / 'hot_weeks_summary.csv'\n",
    "    if hot_path.exists():\n",
    "        hot = pd.read_csv(hot_path)\n",
    "        if not hot.empty:\n",
    "            top_rows = hot.sort_values('mean', ascending=False).head(5)\n",
    "            weeks_str = ', '.join(str(int(w)) for w in top_rows['week'].tolist())\n",
    "            lines.append(f\"历史上均值最高的热点周（Top-5）：{weeks_str}（单位：周序号）\")\n",
    "    # 季节内热点\n",
    "    shot_path = RESULTS_DIR / 'season_hotspot_weeks.csv'\n",
    "    if shot_path.exists():\n",
    "        shot = pd.read_csv(shot_path)\n",
    "        if not shot.empty:\n",
    "            for s in ['Spring','Summer','Autumn','Winter']:\n",
    "                sub = shot[shot['season']==s].sort_values('mean', ascending=False)\n",
    "                top = sub.head(3)\n",
    "                if not top.empty:\n",
    "                    wks = ', '.join(str(int(w)) for w in top['week_in_season'].tolist())\n",
    "                    lines.append(f\"{s}热点周（Top-3）：{wks}\")\n",
    "    if lines:\n",
    "        summary_path = RESULTS_DIR / 'summary_insights.txt'\n",
    "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(lines))\n",
    "        print('保存:', summary_path)\n",
    "    else:\n",
    "        print('暂无可写摘要（可能数据为空或前序单元未运行）。')\n",
    "except Exception as e:\n",
    "    print('生成摘要失败:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ab313",
   "metadata": {},
   "source": [
    "# 热点周的空间分布：思路说明\n",
    "为回答“热点周落在哪些区域更集中”，本节将：\n",
    "- 读取已识别的热点周（基于跨年周均值 Top-N 与阈值筛选）。\n",
    "- 以这些周的火点为子集，与县界做空间连接，统计“县域总量（热点周期间）”。\n",
    "- 绘制：\n",
    "  1) 聚合所有热点周的县域色斑图；\n",
    "  2) 前 Top-K 热点周分别绘制县域色斑图，观察是否空间位置稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 热点周（Top-K）的县域空间分布\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "TOP_K_WEEKS = 3  # 可调：绘制前 K 个热点周\n",
    "\n",
    "if len(fire_gdf) > 0 and COUNTY_SHP.exists():\n",
    "    # 读热点周列表\n",
    "    hot_path = RESULTS_DIR / 'hot_weeks_summary.csv'\n",
    "    if not hot_path.exists():\n",
    "        print('未找到热点周文件，尝试使用 week_of_year_stats.csv 的 Top 周替代。')\n",
    "        stats_path = RESULTS_DIR / 'week_of_year_stats.csv'\n",
    "        if stats_path.exists():\n",
    "            stats = pd.read_csv(stats_path)\n",
    "            hot_weeks = stats.sort_values('mean', ascending=False).head(TOP_K_WEEKS)['week'].astype(int).tolist()\n",
    "        else:\n",
    "            print('week_of_year_stats.csv 也不存在，无法进行热点周空间分析。')\n",
    "            hot_weeks = []\n",
    "    else:\n",
    "        hot = pd.read_csv(hot_path)\n",
    "        if 'week' not in hot.columns:\n",
    "            print('hot_weeks_summary.csv 缺少 week 列，无法继续。')\n",
    "            hot_weeks = []\n",
    "        else:\n",
    "            hot_weeks = hot.dropna(subset=['week']).sort_values('mean', ascending=False)['week'].astype(int).unique().tolist()\n",
    "            hot_weeks = hot_weeks[:TOP_K_WEEKS]\n",
    "\n",
    "    if len(hot_weeks) == 0:\n",
    "        print('没有可用的热点周。')\n",
    "    else:\n",
    "        print('选定热点周（Top-K）:', hot_weeks)\n",
    "        # 确保已计算 iso_week\n",
    "        if 'iso_week' not in fire_gdf.columns:\n",
    "            iso = fire_gdf['datetime'].dt.isocalendar()\n",
    "            fire_gdf['iso_year'] = iso['year'].astype(int)\n",
    "            fire_gdf['iso_week'] = iso['week'].astype(int)\n",
    "\n",
    "        # 读取县界\n",
    "        counties = gpd.read_file(COUNTY_SHP)\n",
    "        try:\n",
    "            if counties.crs is None:\n",
    "                counties = counties.set_crs('EPSG:4326')\n",
    "            elif counties.crs.to_epsg() != 4326:\n",
    "                counties = counties.to_crs(4326)\n",
    "        except Exception:\n",
    "            counties = counties.to_crs(4326)\n",
    "\n",
    "        # 寻找县级标识键\n",
    "        candidate_keys = ['county_id','adcode','code','id','County_ID','COUNTY_ID']\n",
    "        def detect_key(df_cols):\n",
    "            for c in candidate_keys:\n",
    "                if c in df_cols:\n",
    "                    return c\n",
    "            return None\n",
    "\n",
    "        # 1) 聚合所有热点周的总量\n",
    "        sub_all = fire_gdf[fire_gdf['iso_week'].isin(hot_weeks)][['geometry','year']].copy()\n",
    "        join_all = gpd.sjoin(sub_all, counties, how='left', predicate='within')\n",
    "        # 处理 year 列冲突\n",
    "        if 'year_left' in join_all.columns and 'year_right' in join_all.columns:\n",
    "            join_all = join_all.rename(columns={'year_left':'year'}).drop(columns=['year_right'])\n",
    "        elif 'year_left' in join_all.columns:\n",
    "            join_all = join_all.rename(columns={'year_left':'year'})\n",
    "        elif 'year_right' in join_all.columns and 'year' not in join_all.columns:\n",
    "            join_all = join_all.rename(columns={'year_right':'year'})\n",
    "\n",
    "        key = detect_key(join_all.columns)\n",
    "        if key is None:\n",
    "            counties = counties.reset_index().rename(columns={'index':'county_idx'})\n",
    "            join_all = gpd.sjoin(sub_all, counties, how='left', predicate='within')\n",
    "            if 'year_left' in join_all.columns and 'year_right' in join_all.columns:\n",
    "                join_all = join_all.rename(columns={'year_left':'year'}).drop(columns=['year_right'])\n",
    "            elif 'year_left' in join_all.columns:\n",
    "                join_all = join_all.rename(columns={'year_left':'year'})\n",
    "            elif 'year_right' in join_all.columns and 'year' not in join_all.columns:\n",
    "                join_all = join_all.rename(columns={'year_right':'year'})\n",
    "            key = 'county_idx'\n",
    "\n",
    "        county_counts_all = join_all.groupby(key).size().rename('fire_count').reset_index()\n",
    "        county_stats_all = counties.merge(county_counts_all, on=key, how='left')\n",
    "        county_stats_all['fire_count'] = county_stats_all['fire_count'].fillna(0).astype(int)\n",
    "\n",
    "        out_csv_all = RESULTS_DIR / 'county_hot_weeks_fire_counts.csv'\n",
    "        county_stats_all.drop(columns='geometry').to_csv(out_csv_all, index=False)\n",
    "        print('保存:', out_csv_all)\n",
    "\n",
    "        plt.figure(figsize=(8,8))\n",
    "        ax = counties.boundary.plot(edgecolor='lightgray', linewidth=0.3)\n",
    "        county_stats_all.plot(column='fire_count', ax=ax, legend=True, cmap='OrRd', linewidth=0, alpha=0.9)\n",
    "        plt.title(f'县域火点空间分布（聚合热点周：{hot_weeks}）')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        out_png_all = RESULTS_DIR / 'county_hot_weeks_map.png'\n",
    "        plt.savefig(out_png_all, dpi=150)\n",
    "        plt.show()\n",
    "        print('保存:', out_png_all)\n",
    "\n",
    "        # 2) 分别绘制前 TOP_K 周的地图\n",
    "        for w in hot_weeks:\n",
    "            sub_w = fire_gdf[fire_gdf['iso_week']==w][['geometry','year']].copy()\n",
    "            join_w = gpd.sjoin(sub_w, counties, how='left', predicate='within')\n",
    "            if 'year_left' in join_w.columns and 'year_right' in join_w.columns:\n",
    "                join_w = join_w.rename(columns={'year_left':'year'}).drop(columns=['year_right'])\n",
    "            elif 'year_left' in join_w.columns:\n",
    "                join_w = join_w.rename(columns={'year_left':'year'})\n",
    "            elif 'year_right' in join_w.columns and 'year' not in join_w.columns:\n",
    "                join_w = join_w.rename(columns={'year_right':'year'})\n",
    "\n",
    "            key_w = detect_key(join_w.columns)\n",
    "            if key_w is None:\n",
    "                key_w = key  # 回退到上面选择的键\n",
    "\n",
    "            county_counts_w = join_w.groupby(key_w).size().rename('fire_count').reset_index()\n",
    "            county_stats_w = counties.merge(county_counts_w, on=key_w, how='left')\n",
    "            county_stats_w['fire_count'] = county_stats_w['fire_count'].fillna(0).astype(int)\n",
    "\n",
    "            out_csv_w = RESULTS_DIR / f'county_hot_week_{int(w)}_fire_counts.csv'\n",
    "            county_stats_w.drop(columns='geometry').to_csv(out_csv_w, index=False)\n",
    "            print('保存:', out_csv_w)\n",
    "\n",
    "            plt.figure(figsize=(8,8))\n",
    "            ax = counties.boundary.plot(edgecolor='lightgray', linewidth=0.3)\n",
    "            county_stats_w.plot(column='fire_count', ax=ax, legend=True, cmap='OrRd', linewidth=0, alpha=0.9)\n",
    "            plt.title(f'县域火点空间分布（热点周：ISO Week {int(w)}）')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            out_png_w = RESULTS_DIR / f'county_hot_week_{int(w)}_map.png'\n",
    "            plt.savefig(out_png_w, dpi=150)\n",
    "            plt.show()\n",
    "            print('保存:', out_png_w)\n",
    "else:\n",
    "    if not COUNTY_SHP.exists():\n",
    "        print('未找到县界文件:', COUNTY_SHP)\n",
    "    else:\n",
    "        print('无火点数据，跳过热点周空间分析。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9420603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 季节分组的县域空间分布（可选增强）\n",
    "# 将空间分布与季节性关联：按四季分别绘制县域色斑图，便于比较季节差异。\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(fire_gdf) > 0 and COUNTY_SHP.exists():\n",
    "    counties = gpd.read_file(COUNTY_SHP)\n",
    "    try:\n",
    "        if counties.crs is None:\n",
    "            counties = counties.set_crs('EPSG:4326')\n",
    "        elif counties.crs.to_epsg() != 4326:\n",
    "            counties = counties.to_crs(4326)\n",
    "    except Exception:\n",
    "        counties = counties.to_crs(4326)\n",
    "\n",
    "    seasons = ['Spring','Summer','Autumn','Winter']\n",
    "\n",
    "    # 寻找县级标识键\n",
    "    candidate_keys = ['county_id','adcode','code','id','County_ID','COUNTY_ID']\n",
    "    def detect_key(df_cols):\n",
    "        for c in candidate_keys:\n",
    "            if c in df_cols:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    all_rows = []\n",
    "    for s in seasons:\n",
    "        sub = fire_gdf[fire_gdf['season']==s][['geometry','year']].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        join = gpd.sjoin(sub, counties, how='left', predicate='within')\n",
    "        if 'year_left' in join.columns and 'year_right' in join.columns:\n",
    "            join = join.rename(columns={'year_left':'year'}).drop(columns=['year_right'])\n",
    "        elif 'year_left' in join.columns:\n",
    "            join = join.rename(columns={'year_left':'year'})\n",
    "        elif 'year_right' in join.columns and 'year' not in join.columns:\n",
    "            join = join.rename(columns={'year_right':'year'})\n",
    "\n",
    "        key = detect_key(join.columns)\n",
    "        if key is None:\n",
    "            counties = counties.reset_index().rename(columns={'index':'county_idx'})\n",
    "            join = gpd.sjoin(sub, counties, how='left', predicate='within')\n",
    "            if 'year_left' in join.columns and 'year_right' in join.columns:\n",
    "                join = join.rename(columns={'year_left':'year'}).drop(columns=['year_right'])\n",
    "            elif 'year_left' in join.columns:\n",
    "                join = join.rename(columns={'year_left':'year'})\n",
    "            elif 'year_right' in join.columns and 'year' not in join.columns:\n",
    "                join = join.rename(columns={'year_right':'year'})\n",
    "            key = 'county_idx'\n",
    "\n",
    "        # 县域总量（该季汇总）\n",
    "        counts = join.groupby(key).size().rename('fire_count').reset_index()\n",
    "        counts['season'] = s\n",
    "        all_rows.append(counts)\n",
    "\n",
    "        stats_s = counties.merge(counts, on=key, how='left')\n",
    "        stats_s['fire_count'] = stats_s['fire_count'].fillna(0).astype(int)\n",
    "\n",
    "        out_csv_s = RESULTS_DIR / f'county_season_{s}_fire_counts.csv'\n",
    "        stats_s.drop(columns='geometry').to_csv(out_csv_s, index=False)\n",
    "        print('保存:', out_csv_s)\n",
    "\n",
    "        plt.figure(figsize=(8,8))\n",
    "        ax = counties.boundary.plot(edgecolor='lightgray', linewidth=0.3)\n",
    "        stats_s.plot(column='fire_count', ax=ax, legend=True, cmap='OrRd', linewidth=0, alpha=0.9)\n",
    "        plt.title(f'县域火点空间分布（{s}）')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        out_png_s = RESULTS_DIR / f'county_season_{s}_map.png'\n",
    "        plt.savefig(out_png_s, dpi=150)\n",
    "        plt.show()\n",
    "        print('保存:', out_png_s)\n",
    "\n",
    "    if all_rows:\n",
    "        all_df = pd.concat(all_rows, ignore_index=True)\n",
    "        out_all = RESULTS_DIR / 'county_season_fire_counts.csv'\n",
    "        all_df.to_csv(out_all, index=False)\n",
    "        print('保存:', out_all)\n",
    "else:\n",
    "    if not COUNTY_SHP.exists():\n",
    "        print('未找到县界文件:', COUNTY_SHP)\n",
    "    else:\n",
    "        print('无火点数据，跳过季节空间分析。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18442c86",
   "metadata": {},
   "source": [
    "# 核心任务 2：农业焚烧归因（玉米与小麦收获后）\n",
    "本节目标：\n",
    "- 方法学：基于“空间位置相对于耕地 + 时间位置相对于收获季”的双阈组合判定。\n",
    "- 产出：\n",
    "  1) “可能为农业焚烧”的火点比例（%）；\n",
    "  2) 分类点图与县域尺度分类色斑图；\n",
    "  3) 可复用的分类表（CSV）。\n",
    "\n",
    "数据期望：\n",
    "- cropland（耕地）：优先使用 `raw_data/cropland_distribution_and_phenological_data/` 下的矢量（*.shp）或栅格（*.tif）。\n",
    "- harvest calendar（可选）：若目录下有 `harvest_calendar.csv`，优先按区域自定义时段，否则使用默认全国窗口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8be35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 农业焚烧分类与导出（点级 + 县域汇总 + 地图）\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54957d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动耕地标记（优先矢量，其次栅格；标记 fire_gdf['is_cropland']）\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from shapely.strtree import STRtree\n",
    "    _HAS_STRTREE = True\n",
    "except Exception:\n",
    "    _HAS_STRTREE = False\n",
    "\n",
    "try:\n",
    "    from shapely.prepared import prep\n",
    "except Exception:\n",
    "    prep = None\n",
    "\n",
    "\n",
    "def _fallback_point_within(points_gdf: gpd.GeoDataFrame, polygons_gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    \"\"\"降级实现 point-in-polygon，用于缺少空间索引时。\"\"\"\n",
    "    if len(points_gdf) == 0 or len(polygons_gdf) == 0:\n",
    "        result = points_gdf[['index', 'geometry']].copy()\n",
    "        result['index_right'] = [None] * len(result)\n",
    "        return result\n",
    "\n",
    "    result = points_gdf[['index', 'geometry']].copy()\n",
    "    poly_geoms = list(polygons_gdf.geometry)\n",
    "    poly_indices = list(polygons_gdf.index)\n",
    "    matches = []\n",
    "\n",
    "    if _HAS_STRTREE:\n",
    "        tree = STRtree(poly_geoms)\n",
    "        geom_map = {geom.wkb: poly_indices[idx] for idx, geom in enumerate(poly_geoms)}\n",
    "        for geom in result.geometry:\n",
    "            found = None\n",
    "            for candidate in tree.query(geom):\n",
    "                if candidate.contains(geom) or candidate.covers(geom):\n",
    "                    found = geom_map.get(candidate.wkb)\n",
    "                    if found is None:\n",
    "                        found = next((poly_indices[i] for i, g in enumerate(poly_geoms) if g.equals(candidate)), None)\n",
    "                    break\n",
    "            matches.append(found)\n",
    "    else:\n",
    "        prepared = [(prep(poly), idx) for poly, idx in zip(poly_geoms, poly_indices)] if prep is not None else []\n",
    "        for geom in result.geometry:\n",
    "            found = None\n",
    "            for prepared_poly, idx in prepared:\n",
    "                if prepared_poly.contains(geom) or prepared_poly.covers(geom):\n",
    "                    found = idx\n",
    "                    break\n",
    "            if found is None:\n",
    "                for idx, poly in zip(poly_indices, poly_geoms):\n",
    "                    if poly.contains(geom) or poly.covers(geom):\n",
    "                        found = idx\n",
    "                        break\n",
    "            matches.append(found)\n",
    "\n",
    "    result['index_right'] = matches\n",
    "    return result\n",
    "\n",
    "\n",
    "def _geometry_to_xy(geom):\n",
    "    \"\"\"为点/多点/面几何提取一个代表性的 (x, y) 坐标，用于栅格采样。\"\"\"\n",
    "    if geom is None or geom.is_empty:\n",
    "        return None\n",
    "    gtype = geom.geom_type\n",
    "    if gtype == 'Point':\n",
    "        return geom.x, geom.y\n",
    "    if gtype in {'MultiPoint', 'GeometryCollection'}:\n",
    "        for part in geom.geoms:\n",
    "            xy = _geometry_to_xy(part)\n",
    "            if xy is not None:\n",
    "                return xy\n",
    "        return None\n",
    "    centroid = geom.centroid\n",
    "    if centroid.is_empty:\n",
    "        return None\n",
    "    return centroid.x, centroid.y\n",
    "\n",
    "\n",
    "# 可选：强制重算 is_cropland（用于修正之前阈值/越界带来的异常）\n",
    "FORCE_RECOMPUTE_IS_CROPLAND = True\n",
    "\n",
    "CROP_DIR = REPO_ROOT / 'raw_data' / 'cropland_distribution_and_phenological_data'\n",
    "\n",
    "if 'fire_gdf' not in globals() or fire_gdf is None or len(fire_gdf) == 0:\n",
    "    raise RuntimeError('fire_gdf 缺失，请先运行数据加载或分类单元中的兜底装载。')\n",
    "\n",
    "# 若已有有效 is_cropland，且不强制重算，则跳过\n",
    "if (not FORCE_RECOMPUTE_IS_CROPLAND) and ('is_cropland' in fire_gdf.columns) and (fire_gdf['is_cropland'].sum() > 0):\n",
    "    print('检测到已有有效 is_cropland，不再重复标记。')\n",
    "else:\n",
    "    # 如存在旧列，先清空\n",
    "    if 'is_cropland' in fire_gdf.columns:\n",
    "        del fire_gdf['is_cropland']\n",
    "\n",
    "    shp_candidates = list(CROP_DIR.rglob('*.shp')) if CROP_DIR.exists() else []\n",
    "    tif_candidates = list(CROP_DIR.rglob('*.tif')) if CROP_DIR.exists() else []\n",
    "\n",
    "    marked = False\n",
    "\n",
    "    # 1) 矢量耕地优先：点落在多边形内即视为耕地\n",
    "    if shp_candidates:\n",
    "        try:\n",
    "            crop_shp = max(shp_candidates, key=lambda p: p.stat().st_size)\n",
    "            print('使用耕地矢量：', crop_shp)\n",
    "            cropland_gdf = gpd.read_file(crop_shp)\n",
    "            if cropland_gdf.crs is None:\n",
    "                cropland_gdf = cropland_gdf.set_crs('EPSG:4326')\n",
    "            elif cropland_gdf.crs.to_epsg() != 4326:\n",
    "                cropland_gdf = cropland_gdf.to_crs(4326)\n",
    "\n",
    "            left = gpd.GeoDataFrame(\n",
    "                fire_gdf[['geometry']].reset_index(),\n",
    "                geometry='geometry',\n",
    "                crs=fire_gdf.crs\n",
    "            )\n",
    "            right = gpd.GeoDataFrame(\n",
    "                cropland_gdf[['geometry']],\n",
    "                geometry='geometry',\n",
    "                crs=cropland_gdf.crs\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                join = gpd.sjoin(left, right, how='left', predicate='within')\n",
    "            except Exception as exc:\n",
    "                if 'Spatial indexes require' in str(exc):\n",
    "                    warnings.warn('未检测到 rtree/pygeos，使用 Shapely 兜底空间关联，速度可能较慢。')\n",
    "                    join = _fallback_point_within(left, right)\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "            is_crop = join['index_right'].notna().values\n",
    "            fire_gdf['is_cropland'] = is_crop\n",
    "            print('矢量判定完成：is_cropland=True 计数 =', int(fire_gdf['is_cropland'].sum()))\n",
    "            marked = True\n",
    "        except Exception as e:\n",
    "            print('矢量耕地判定失败：', e)\n",
    "\n",
    "    # 2) 栅格耕地：采样栅格值，考虑 nodata 与范围，使用自适应阈值\n",
    "    if not marked and tif_candidates:\n",
    "        try:\n",
    "            import numpy as np\n",
    "            import rasterio\n",
    "\n",
    "            raster_override = globals().get('cropland_raster_path')\n",
    "            if raster_override:\n",
    "                raw_candidates = [Path(raster_override)]\n",
    "            else:\n",
    "                raw_candidates = tif_candidates\n",
    "\n",
    "            raster_files = []\n",
    "            for candidate in raw_candidates:\n",
    "                candidate = Path(candidate)\n",
    "                if candidate.is_dir():\n",
    "                    raster_files.extend(sorted(candidate.rglob('*.tif')))\n",
    "                elif candidate.suffix.lower() == '.tif' and candidate.exists():\n",
    "                    raster_files.append(candidate)\n",
    "\n",
    "            if not raster_files:\n",
    "                raise FileNotFoundError('未找到可用的耕地栅格 (.tif) 文件，请确认路径。')\n",
    "\n",
    "            rpath = max(raster_files, key=lambda p: p.stat().st_size).resolve()\n",
    "            print('使用耕地栅格：', rpath)\n",
    "\n",
    "            with rasterio.open(rpath) as src:\n",
    "                xy_coords = [_geometry_to_xy(geom) for geom in fire_gdf.geometry]\n",
    "                valid_pairs = [(idx, xy) for idx, xy in enumerate(xy_coords) if xy is not None]\n",
    "                arr = np.full(len(xy_coords), np.nan, dtype='float32')\n",
    "\n",
    "                if valid_pairs:\n",
    "                    bounds = src.bounds\n",
    "                    inside = []\n",
    "                    for idx, (x, y) in valid_pairs:\n",
    "                        in_bounds = (bounds.left <= x <= bounds.right) and (bounds.bottom <= y <= bounds.top)\n",
    "                        if in_bounds:\n",
    "                            inside.append((idx, (x, y)))\n",
    "\n",
    "                    if inside:\n",
    "                        sample_pts = [pt for _, pt in inside]\n",
    "                        sample_idx = [idx for idx, _ in inside]\n",
    "                        samp = np.array(list(src.sample(sample_pts))).squeeze()\n",
    "                        if samp.ndim == 0:\n",
    "                            samp = np.array([samp], dtype='float32')\n",
    "                        else:\n",
    "                            samp = samp.astype('float32', copy=False)\n",
    "\n",
    "                        ndv = src.nodata\n",
    "                        if ndv is not None and np.isfinite(ndv):\n",
    "                            samp = np.where(np.isclose(samp, ndv), np.nan, samp)\n",
    "\n",
    "                        arr[sample_idx] = samp\n",
    "\n",
    "                finite = np.isfinite(arr)\n",
    "                if finite.any():\n",
    "                    vmax = float(np.nanmax(arr))\n",
    "                    if vmax <= 1.0:\n",
    "                        thr = 0.5\n",
    "                        rule = '> 0.5'\n",
    "                    elif vmax <= 100.0:\n",
    "                        thr = 50.0\n",
    "                        rule = '>= 50%'\n",
    "                    else:\n",
    "                        thr = 0.0\n",
    "                        rule = '> 0'\n",
    "                    is_crop = (finite & (arr > thr))\n",
    "                else:\n",
    "                    is_crop = np.zeros(len(arr), dtype=bool)\n",
    "                    thr = None\n",
    "                    rule = 'no-data'\n",
    "\n",
    "                fire_gdf['is_cropland'] = is_crop\n",
    "                true_cnt = int(is_crop.sum())\n",
    "                print(f'栅格判定完成（阈值规则 {rule}）：is_cropland=True 计数 = {true_cnt}')\n",
    "                marked = True\n",
    "        except ImportError:\n",
    "            print('需要 rasterio 来采样栅格，请先安装：pip install rasterio（或在 Notebook 内安装）。')\n",
    "        except Exception as e:\n",
    "            print('栅格耕地判定失败：', e)\n",
    "\n",
    "    if not marked:\n",
    "        if 'is_cropland' not in fire_gdf.columns:\n",
    "            fire_gdf['is_cropland'] = False\n",
    "        print('未能完成耕地标记，已兜底 is_cropland=False（请检查 cropland 数据与依赖）。')\n",
    "\n",
    "# 简要汇总\n",
    "total = len(fire_gdf)\n",
    "true_cnt = int(fire_gdf['is_cropland'].sum()) if 'is_cropland' in fire_gdf.columns else 0\n",
    "print(f'is_cropland 汇总：True={true_cnt} / Total={total} ({true_cnt/total*100 if total else 0:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 农业焚烧分类与导出（点级 + 县域汇总 + 地图）——稳健版（含兜底加载与缺失列补全）\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 统一中文字体，抑制中文缺字警告\n",
    "try:\n",
    "    from matplotlib import font_manager, rcParams\n",
    "    preferred = ['Microsoft YaHei','SimHei','Source Han Sans SC','Noto Sans CJK SC']\n",
    "    available = {f.name for f in font_manager.fontManager.ttflist}\n",
    "    hit = None\n",
    "    for name in preferred:\n",
    "        if name in available:\n",
    "            hit = name\n",
    "            break\n",
    "    if hit:\n",
    "        rcParams['font.sans-serif'] = [hit] + rcParams.get('font.sans-serif', [])\n",
    "        rcParams['axes.unicode_minus'] = False\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 0) 路径与目录兜底\n",
    "if 'REPO_ROOT' not in globals() or 'RESULTS_DIR' not in globals() or 'RAW_DIR' not in globals() or 'FIRE_DIR' not in globals() or 'COUNTY_SHP' not in globals():\n",
    "    def detect_repo_root(start: Path = Path.cwd()) -> Path:\n",
    "        for p in [start] + list(start.parents):\n",
    "            if (p / 'raw_data').exists():\n",
    "                return p\n",
    "        return start.parent if start.name == 'script' else start\n",
    "    REPO_ROOT = detect_repo_root()\n",
    "    RAW_DIR = REPO_ROOT / 'raw_data'\n",
    "    FIRE_DIR = RAW_DIR / 'satellite_fire_data'\n",
    "    COUNTY_SHP = RAW_DIR / 'chn_county' / 'chn_county.shp'\n",
    "    RESULTS_DIR = REPO_ROOT / 'results'\n",
    "else:\n",
    "    # 确保所有路径变量都是 Path 对象\n",
    "    if not isinstance(RESULTS_DIR, Path):\n",
    "        RESULTS_DIR = Path(RESULTS_DIR)\n",
    "    if not isinstance(FIRE_DIR, Path):\n",
    "        FIRE_DIR = Path(FIRE_DIR)\n",
    "    if not isinstance(RAW_DIR, Path):\n",
    "        RAW_DIR = Path(RAW_DIR)\n",
    "    if not isinstance(REPO_ROOT, Path):\n",
    "        REPO_ROOT = Path(REPO_ROOT)\n",
    "    if not isinstance(COUNTY_SHP, Path):\n",
    "        COUNTY_SHP = Path(COUNTY_SHP)\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_TASK2 = RESULTS_DIR / 'task2' \n",
    "RESULTS_TASK2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) 基础工具兜底\n",
    "if 'find_column' not in globals():\n",
    "    def find_column(cols, candidates):\n",
    "        for cand in candidates:\n",
    "            for col in cols:\n",
    "                if col.lower() == cand.lower():\n",
    "                    return col\n",
    "        return None\n",
    "\n",
    "if 'build_datetime' not in globals():\n",
    "    def build_datetime(df):\n",
    "        date_col = find_column(df.columns, ['acq_date', 'date', 'acq-date'])\n",
    "        time_col = find_column(df.columns, ['acq_time', 'time', 'acq-time'])\n",
    "        dt = None\n",
    "        if date_col is not None and time_col is not None:\n",
    "            def _fmt_time(t):\n",
    "                try:\n",
    "                    s = str(int(t)).zfill(4)\n",
    "                    return f\"{s[:2]}:{s[2:]}\"\n",
    "                except Exception:\n",
    "                    return None\n",
    "            times = df[time_col].apply(_fmt_time)\n",
    "            dt = pd.to_datetime(df[date_col].astype(str) + ' ' + times.astype(str), errors='coerce')\n",
    "        elif date_col is not None:\n",
    "            dt = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        else:\n",
    "            ts_col = find_column(df.columns, ['timestamp'])\n",
    "            if ts_col is not None:\n",
    "                dt = pd.to_datetime(df[ts_col], errors='coerce')\n",
    "        if dt is None:\n",
    "            raise ValueError('未能识别日期/时间列，请检查原始 CSV 列名。')\n",
    "        df['datetime'] = dt\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "        df['year'] = df['datetime'].dt.year\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        MONTH2SEASON = {12:'Winter',1:'Winter',2:'Winter',3:'Spring',4:'Spring',5:'Spring',6:'Summer',7:'Summer',8:'Summer',9:'Autumn',10:'Autumn',11:'Autumn'}\n",
    "        df['season'] = df['month'].map(MONTH2SEASON)\n",
    "        return df\n",
    "\n",
    "if 'to_geodf' not in globals():\n",
    "    def to_geodf(df):\n",
    "        lon_col = find_column(df.columns, ['longitude', 'lon', 'long'])\n",
    "        lat_col = find_column(df.columns, ['latitude', 'lat'])\n",
    "        if lon_col is None or lat_col is None:\n",
    "            raise ValueError('未找到经纬度列（longitude/latitude 或 lon/lat）。')\n",
    "        geometry = [Point(xy) for xy in zip(df[lon_col].astype(float), df[lat_col].astype(float))]\n",
    "        gdf = gpd.GeoDataFrame(df.copy(), geometry=geometry, crs='EPSG:4326')\n",
    "        return gdf\n",
    "\n",
    "# 2) 数据兜底：若 fire_gdf 缺失则自动装载\n",
    "if 'fire_gdf' not in globals() or fire_gdf is None or len(fire_gdf) == 0:\n",
    "    from glob import glob\n",
    "    # 确保 FIRE_DIR 是 Path 对象\n",
    "    if not isinstance(FIRE_DIR, Path):\n",
    "        FIRE_DIR = Path(FIRE_DIR)\n",
    "    \n",
    "    csv_paths = sorted(FIRE_DIR.glob('modis_*_china.csv'))\n",
    "    csv_paths = [str(p) for p in csv_paths]  # 转为字符串列表以兼容 pd.read_csv\n",
    "    frames = []\n",
    "\n",
    "    for p in csv_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "            df = build_datetime(df)\n",
    "            lon_col = find_column(df.columns, ['longitude', 'lon', 'long'])\n",
    "            lat_col = find_column(df.columns, ['latitude', 'lat'])\n",
    "            if lon_col and lat_col:\n",
    "                # 粗略范围裁剪到中国，避免异常点\n",
    "                df = df[(df[lon_col].between(70, 140)) & (df[lat_col].between(15, 55))]\n",
    "            frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'读取失败 {p}: {e}')\n",
    "    fire_df = pd.DataFrame() if not frames else pd.concat(frames, ignore_index=True)\n",
    "    fire_gdf = to_geodf(fire_df).set_crs('EPSG:4326', allow_override=True) if not fire_df.empty else gpd.GeoDataFrame(columns=['datetime','year','month','season','geometry'], geometry='geometry', crs='EPSG:4326')\n",
    "print('fire_gdf 就绪，记录数:', len(fire_gdf))\n",
    "\n",
    "# 3) 时间窗口标记兜底：若未运行专门单元则按全国默认窗口生成\n",
    "if 'in_wheat_window' not in fire_gdf.columns or 'in_corn_window' not in fire_gdf.columns:\n",
    "    from datetime import datetime\n",
    "    DEFAULT_WINDOWS = [\n",
    "        {'crop':'wheat', 'start':(5,15), 'end':(6,30)},   # 冬小麦\n",
    "        {'crop':'wheat', 'start':(8,1),  'end':(9,15)},   # 北方春小麦/补充\n",
    "        {'crop':'corn',  'start':(9,1),  'end':(11,15)},  # 玉米\n",
    "    ]\n",
    "    def in_mmdd_window(dt: pd.Timestamp, sm, sd, em, ed):\n",
    "        if pd.isna(dt):\n",
    "            return False\n",
    "        m, d = dt.month, dt.day\n",
    "        if (sm,sd) <= (em,ed):\n",
    "            return (m,d) >= (sm,sd) and (m,d) <= (em,ed)\n",
    "        else:\n",
    "            return (m,d) >= (sm,sd) or (m,d) <= (em,ed)\n",
    "    fire_gdf['in_wheat_window'] = False\n",
    "    fire_gdf['in_corn_window'] = False\n",
    "    for win in DEFAULT_WINDOWS:\n",
    "        flag = fire_gdf['datetime'].apply(lambda t: in_mmdd_window(t, win['start'][0], win['start'][1], win['end'][0], win['end'][1]))\n",
    "        if win['crop'] == 'wheat':\n",
    "            fire_gdf['in_wheat_window'] = fire_gdf['in_wheat_window'] | flag\n",
    "        elif win['crop'] == 'corn':\n",
    "            fire_gdf['in_corn_window'] = fire_gdf['in_corn_window'] | flag\n",
    "    print('已按默认全国窗口补齐 in_wheat_window / in_corn_window 标记。')\n",
    "\n",
    "# 4) 空间耕地标记兜底：若缺失 is_cropland 列，则先置为 False 并提示\n",
    "if 'is_cropland' not in fire_gdf.columns:\n",
    "    fire_gdf['is_cropland'] = False\n",
    "    print('提示：未检测到 is_cropland，已临时置为 False（可先运行耕地加载单元获得更准确判定）。')\n",
    "\n",
    "# 5) 分类规则：空间（在耕地） AND 时间（在小麦或玉米收获窗口）\n",
    "fire_gdf['ag_burning'] = fire_gdf['is_cropland'] & (fire_gdf['in_wheat_window'] | fire_gdf['in_corn_window'])\n",
    "\n",
    "# 可选细化：标记具体作物窗口\n",
    "fire_gdf['in_any_window'] = fire_gdf['in_wheat_window'] | fire_gdf['in_corn_window']\n",
    "fire_gdf['ag_label'] = np.select(\n",
    "    [fire_gdf['ag_burning'], fire_gdf['is_cropland'] & ~fire_gdf['in_any_window'], ~fire_gdf['is_cropland'] & fire_gdf['in_any_window']],\n",
    "    ['likely_agri_burning', 'cropland_out_of_harvest', 'non_cropland_in_harvest'],\n",
    "    default='other_or_uncertain'\n",
    ")\n",
    "\n",
    "# 6) 量化估计\n",
    "summary = fire_gdf['ag_label'].value_counts().rename_axis('label').reset_index(name='count')\n",
    "summary['percent'] = (summary['count'] / len(fire_gdf) * 100).round(2)\n",
    "summary_out = RESULTS_TASK2 / 'ag_burning_summary.csv'\n",
    "summary.to_csv(summary_out, index=False)\n",
    "print('保存:', summary_out)\n",
    "print(summary)\n",
    "\n",
    "# 7) 导出点级分类（轻量列）\n",
    "cols_export = ['datetime','year','month','season','is_cropland','in_wheat_window','in_corn_window','ag_label','geometry']\n",
    "classified_points = fire_gdf[cols_export].copy()\n",
    "classified_points_path = RESULTS_TASK2 / 'ag_burning_classified_points.geojson'\n",
    "classified_points.to_file(classified_points_path, driver='GeoJSON')\n",
    "print('保存:', classified_points_path)\n",
    "\n",
    "# 8) 点图（分类别分层绘制，避免 color 与 column 参数冲突）\n",
    "N = len(fire_gdf)\n",
    "sample_rate = 1.0 if N <= 150000 else min(150000/N, 1.0)\n",
    "plot_df = fire_gdf.sample(frac=sample_rate, random_state=42) if sample_rate < 1.0 else fire_gdf\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "base = None\n",
    "try:\n",
    "    if Path(COUNTY_SHP).exists():\n",
    "        counties = gpd.read_file(COUNTY_SHP)\n",
    "        if counties.crs is None:\n",
    "            counties = counties.set_crs('EPSG:4326')\n",
    "        elif counties.crs.to_epsg() != 4326:\n",
    "            counties = counties.to_crs(4326)\n",
    "        base = counties.boundary.plot(edgecolor='lightgray', linewidth=0.3)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "palette = {\n",
    "    'likely_agri_burning':'#D7191C',\n",
    "    'cropland_out_of_harvest':'#FDAE61',\n",
    "    'non_cropland_in_harvest':'#2C7FB8',\n",
    "    'other_or_uncertain':'#AAAAAA'\n",
    "}\n",
    "for lab, color in palette.items():\n",
    "    sub = plot_df[plot_df['ag_label'] == lab]\n",
    "    if len(sub) > 0:\n",
    "        sub.plot(ax=base, markersize=2, alpha=0.6, color=color, label=lab)\n",
    "plt.title('火点分类（农业焚烧归因）')\n",
    "plt.axis('off')\n",
    "plt.legend(markerscale=4, fontsize=8, frameon=True)\n",
    "plt.tight_layout()\n",
    "points_map = RESULTS_TASK2 / 'ag_burning_points_map.png'\n",
    "plt.savefig(points_map, dpi=150)\n",
    "plt.show()\n",
    "print('保存:', points_map)\n",
    "\n",
    "# 9) 县域汇总与地图\n",
    "try:\n",
    "    if 'ag_label' not in fire_gdf.columns:\n",
    "        raise ValueError('缺少 ag_label 列')\n",
    "    if not Path(COUNTY_SHP).exists():\n",
    "        raise FileNotFoundError(f'未找到县界文件: {COUNTY_SHP}')\n",
    "\n",
    "    counties = gpd.read_file(COUNTY_SHP)\n",
    "    if counties.crs is None:\n",
    "        counties = counties.set_crs('EPSG:4326')\n",
    "    elif counties.crs.to_epsg() != 4326:\n",
    "        counties = counties.to_crs(4326)\n",
    "\n",
    "    join = gpd.sjoin(fire_gdf[['geometry','ag_label']], counties, how='left', predicate='within')\n",
    "\n",
    "    # 选择县级键\n",
    "    key = None\n",
    "    for c in ['county_id','adcode','code','id','County_ID','COUNTY_ID']:\n",
    "        if c in join.columns:\n",
    "            key = c\n",
    "            break\n",
    "    if key is None:\n",
    "        counties = counties.reset_index().rename(columns={'index':'county_idx'})\n",
    "        join = gpd.sjoin(fire_gdf[['geometry','ag_label']], counties, how='left', predicate='within')\n",
    "        key = 'county_idx'\n",
    "\n",
    "    # 每县“likely_agri_burning”计数\n",
    "    cnt = join[join['ag_label']=='likely_agri_burning'].groupby(key).size().rename('ag_burn_count').reset_index()\n",
    "    stats = counties.merge(cnt, on=key, how='left')\n",
    "    stats['ag_burn_count'] = stats['ag_burn_count'].fillna(0).astype(int)\n",
    "\n",
    "    out_csv = RESULTS_TASK2 / 'county_ag_burning_counts.csv'\n",
    "    stats.drop(columns='geometry').to_csv(out_csv, index=False)\n",
    "    print('保存:', out_csv)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = counties.boundary.plot(edgecolor='lightgray', linewidth=0.3)\n",
    "    stats.plot(column='ag_burn_count', ax=ax, legend=True, cmap='OrRd', linewidth=0, alpha=0.9)\n",
    "    plt.title('县域“农业焚烧”火点数')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    county_map = RESULTS_TASK2 / 'county_ag_burning_map.png'\n",
    "    plt.savefig(county_map, dpi=150)\n",
    "    plt.show()\n",
    "    print('保存:', county_map)\n",
    "except Exception as e:\n",
    "    print('县域汇总绘图失败：', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收获季时间窗口（可选读取配置，否则使用默认全国窗口）\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path  # 确保导入 Path\n",
    "\n",
    "# 确保 CROP_DIR 已定义\n",
    "if 'CROP_DIR' not in globals():\n",
    "    if 'REPO_ROOT' in globals() and isinstance(REPO_ROOT, (Path, str)):\n",
    "        if not isinstance(REPO_ROOT, Path):\n",
    "            REPO_ROOT = Path(REPO_ROOT)\n",
    "        CROP_DIR = REPO_ROOT / 'raw_data' / 'cropland_distribution_and_phenological_data'\n",
    "    else:\n",
    "        # 如果连 REPO_ROOT 都没有定义，尝试重新检测\n",
    "        def detect_repo_root(start: Path = Path.cwd()) -> Path:\n",
    "            for p in [start] + list(start.parents):\n",
    "                if (p / 'raw_data').exists():\n",
    "                    return p\n",
    "            return start.parent if start.name == 'script' else start\n",
    "        REPO_ROOT = detect_repo_root()\n",
    "        CROP_DIR = REPO_ROOT / 'raw_data' / 'cropland_distribution_and_phenological_data'\n",
    "\n",
    "CAL_DIR = CROP_DIR\n",
    "cal_path = CAL_DIR / 'harvest_calendar.csv' if CAL_DIR.exists() else None\n",
    "calendar_df = None\n",
    "if cal_path and cal_path.exists():\n",
    "    try:\n",
    "        calendar_df = pd.read_csv(cal_path)\n",
    "        print('使用自定义 harvest_calendar.csv')\n",
    "        display(calendar_df.head())\n",
    "    except Exception as e:\n",
    "        print('读取 harvest_calendar.csv 失败，使用默认窗口。原因:', e)\n",
    "else:\n",
    "    print('未发现 harvest_calendar.csv，使用默认窗口。')\n",
    "\n",
    "# 默认全国窗口（可按需微调）：\n",
    "DEFAULT_WINDOWS = [\n",
    "    # 小麦（冬小麦）：5/15–6/30\n",
    "    {'crop':'wheat', 'start':(5,15), 'end':(6,30)},\n",
    "    # 小麦（春小麦/北方局地）：8/01–9/15\n",
    "    {'crop':'wheat', 'start':(8,1), 'end':(9,15)},\n",
    "    # 玉米：9/01–11/15\n",
    "    {'crop':'corn',  'start':(9,1), 'end':(11,15)}\n",
    "]\n",
    "\n",
    "def in_mmdd_window(dt: pd.Timestamp, start_m, start_d, end_m, end_d):\n",
    "    if pd.isna(dt):\n",
    "        return False\n",
    "    m = dt.month; d = dt.day\n",
    "    start = (start_m, start_d)\n",
    "    end = (end_m, end_d)\n",
    "    if start <= end:\n",
    "        return (m, d) >= start and (m, d) <= end\n",
    "    else:\n",
    "        # 跨年窗口（这里不使用，但保留逻辑）\n",
    "        return (m, d) >= start or (m, d) <= end\n",
    "\n",
    "# 为每个火点计算 in_wheat_window / in_corn_window 标记\n",
    "fire_gdf['in_wheat_window'] = False\n",
    "fire_gdf['in_corn_window'] = False\n",
    "\n",
    "if calendar_df is not None:\n",
    "    # 若提供了日历，需将点映射到区域（县/省）后按区域窗口判定。\n",
    "    # 这里先尝试县级映射；若列名中包含 region/adcode/code 等则按该键匹配。\n",
    "    # 简化：按全国统一窗口作为兜底，区域规则留作后续扩展。\n",
    "    print('当前版本按全国默认窗口 + 可选区域覆盖。若需严格区域化，请提供可匹配的区域编码列名，并说明对应县界字段。')\n",
    "\n",
    "# 默认窗口打标\n",
    "for win in DEFAULT_WINDOWS:\n",
    "    crop = win['crop']\n",
    "    sm, sd = win['start']\n",
    "    em, ed = win['end']\n",
    "    flag = fire_gdf['datetime'].apply(lambda t: in_mmdd_window(t, sm, sd, em, ed))\n",
    "    if crop == 'wheat':\n",
    "        fire_gdf['in_wheat_window'] = fire_gdf['in_wheat_window'] | flag\n",
    "    elif crop == 'corn':\n",
    "        fire_gdf['in_corn_window'] = fire_gdf['in_corn_window'] | flag\n",
    "\n",
    "print('时间窗口标记完成。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务2运行环境与数据保障（路径/变量自检）\n",
    "# - 确保 REPO_ROOT/RAW_DIR/FIRE_DIR/COUNTY_SHP/RESULTS_DIR 存在\n",
    "# - 定义 TASK2 结果目录 results/task2\n",
    "# - 若 fire_gdf 未定义或为空，则在本单元内自动装载一次\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 1) 路径变量兜底\n",
    "if 'REPO_ROOT' not in globals() or 'RAW_DIR' not in globals() or 'FIRE_DIR' not in globals() or 'COUNTY_SHP' not in globals() or 'RESULTS_DIR' not in globals():\n",
    "    def detect_repo_root(start: Path = Path.cwd()) -> Path:\n",
    "        for p in [start] + list(start.parents):\n",
    "            if (p / 'raw_data').exists():\n",
    "                return p\n",
    "        return start.parent if start.name == 'script' else start\n",
    "    REPO_ROOT = detect_repo_root()\n",
    "    RAW_DIR = REPO_ROOT / 'raw_data'\n",
    "    FIRE_DIR = RAW_DIR / 'satellite_fire_data'\n",
    "    COUNTY_SHP = RAW_DIR / 'chn_county' / 'chn_county.shp'\n",
    "    RESULTS_DIR = REPO_ROOT / 'results'\n",
    "    RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    # 关键修复：确保所有路径变量都是 Path 对象\n",
    "    if not isinstance(REPO_ROOT, Path):\n",
    "        REPO_ROOT = Path(REPO_ROOT)\n",
    "    if not isinstance(RAW_DIR, Path):\n",
    "        RAW_DIR = Path(RAW_DIR)\n",
    "    if not isinstance(FIRE_DIR, Path):\n",
    "        FIRE_DIR = Path(FIRE_DIR)\n",
    "    if not isinstance(COUNTY_SHP, Path):\n",
    "        COUNTY_SHP = Path(COUNTY_SHP)\n",
    "    if not isinstance(RESULTS_DIR, Path):\n",
    "        RESULTS_DIR = Path(RESULTS_DIR)\n",
    "\n",
    "# 2) 定义 Task2 独立结果目录\n",
    "RESULTS_TASK2 = RESULTS_DIR / 'task2'\n",
    "RESULTS_TASK2.mkdir(parents=True, exist_ok=True)\n",
    "print('Task2 results dir:', RESULTS_TASK2)\n",
    "\n",
    "# 3) 若缺少辅助函数，提供兜底实现\n",
    "if 'find_column' not in globals():\n",
    "    def find_column(cols, candidates):\n",
    "        for cand in candidates:\n",
    "            for col in cols:\n",
    "                if col.lower() == cand.lower():\n",
    "                    return col\n",
    "        return None\n",
    "\n",
    "if 'build_datetime' not in globals():\n",
    "    def build_datetime(df):\n",
    "        date_col = find_column(df.columns, ['acq_date', 'date', 'acq-date'])\n",
    "        time_col = find_column(df.columns, ['acq_time', 'time', 'acq-time'])\n",
    "        dt = None\n",
    "        if date_col is not None and time_col is not None:\n",
    "            def _fmt_time(t):\n",
    "                try:\n",
    "                    s = str(int(t)).zfill(4)\n",
    "                    return f\"{s[:2]}:{s[2:]}\"\n",
    "                except Exception:\n",
    "                    return None\n",
    "            times = df[time_col].apply(_fmt_time)\n",
    "            dt = pd.to_datetime(df[date_col].astype(str) + ' ' + times.astype(str), errors='coerce')\n",
    "        elif date_col is not None:\n",
    "            dt = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        else:\n",
    "            ts_col = find_column(df.columns, ['timestamp'])\n",
    "            if ts_col is not None:\n",
    "                dt = pd.to_datetime(df[ts_col], errors='coerce')\n",
    "        if dt is None:\n",
    "            raise ValueError('未能识别日期/时间列，请检查原始 CSV 列名。')\n",
    "        df['datetime'] = dt\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "        df['year'] = df['datetime'].dt.year\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        # 简化季节映射\n",
    "        MONTH2SEASON = {12:'Winter',1:'Winter',2:'Winter',3:'Spring',4:'Spring',5:'Spring',6:'Summer',7:'Summer',8:'Summer',9:'Autumn',10:'Autumn',11:'Autumn'}\n",
    "        df['season'] = df['month'].map(MONTH2SEASON)\n",
    "        return df\n",
    "\n",
    "if 'to_geodf' not in globals():\n",
    "    def to_geodf(df):\n",
    "        lon_col = find_column(df.columns, ['longitude', 'lon', 'long'])\n",
    "        lat_col = find_column(df.columns, ['latitude', 'lat'])\n",
    "        if lon_col is None or lat_col is None:\n",
    "            raise ValueError('未找到经纬度列（longitude/latitude 或 lon/lat）。')\n",
    "        geometry = [Point(xy) for xy in zip(df[lon_col].astype(float), df[lat_col].astype(float))]\n",
    "        gdf = gpd.GeoDataFrame(df.copy(), geometry=geometry, crs='EPSG:4326')\n",
    "        return gdf\n",
    "\n",
    "# 4) 若 fire_gdf 未就绪，则自动装载\n",
    "if 'fire_gdf' not in globals() or fire_gdf is None or len(fire_gdf) == 0:\n",
    "    from glob import glob\n",
    "    if not isinstance(FIRE_DIR, Path):\n",
    "        FIRE_DIR = Path(FIRE_DIR)\n",
    "    \n",
    "    csv_paths = sorted(FIRE_DIR.glob('modis_*_china.csv'))\n",
    "    csv_paths = [str(p) for p in csv_paths]  # 转为字符串列表以兼容 pd.read_csv\n",
    "\n",
    "    frames = []\n",
    "    for p in csv_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "            df = build_datetime(df)\n",
    "            lon_col = find_column(df.columns, ['longitude', 'lon', 'long'])\n",
    "            lat_col = find_column(df.columns, ['latitude', 'lat'])\n",
    "            if lon_col and lat_col:\n",
    "                df = df[(df[lon_col].between(70, 140)) & (df[lat_col].between(15, 55))]\n",
    "            try:\n",
    "                year_in_name = int(Path(p).stem.split('_')[1])\n",
    "                df['year_from_fname'] = year_in_name\n",
    "            except Exception:\n",
    "                df['year_from_fname'] = df['year']\n",
    "            frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'读取失败 {p}: {e}')\n",
    "    fire_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "    if not fire_df.empty:\n",
    "        fire_gdf = to_geodf(fire_df).set_crs('EPSG:4326', allow_override=True)\n",
    "    else:\n",
    "        fire_gdf = gpd.GeoDataFrame(columns=['datetime','year','month','season','geometry'], geometry='geometry', crs='EPSG:4326')\n",
    "print('fire_gdf 就绪，记录数:', len(fire_gdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452df211",
   "metadata": {},
   "source": [
    "## 任务2与改进版之间的说明（为什么原始结果被低估、改进的动机）\n",
    "\n",
    "本研究的核心问题是：在多大程度上可将观测到的火点归因为收获后秸秆焚烧。原始任务2按“全国火点 × 耕地覆盖 × 收获窗口”的框架计算，但本仓库目前提供的耕地分布与物候数据仅覆盖黑龙江省（2010–2019），未覆盖全国其他省份。\n",
    "\n",
    "这导致两个直接后果：\n",
    "- 覆盖错配：当用“仅黑龙江的作物栅格”去匹配“全国范围的火点”时，黑龙江以外的火点大多被判为“非耕地”。\n",
    "- 归因被系统性低估：许多本应属于“耕地附近”的火点被划入“非耕地/不确定”，使得“likely_agri_burning”的全国占比被压低到 ~1.77%。\n",
    "\n",
    "此外，还有两点会进一步压低归因：\n",
    "- 未考虑“田边焚烧”：若不对耕地做邻近缓冲，田块边界附近的焚烧点经常被误判为非耕地。\n",
    "- 收获窗口未分省：全国统一窗口无法反映南北与地貌差异，时间匹配会在不同地区出现偏宽/偏窄。\n",
    "\n",
    "因此，我们增加了一个“改进版（轻量）”以提供“在数据覆盖区域内”的可信结论，并为未来全国化铺路：\n",
    "1) 覆盖感知：先用县域边界筛选出“黑龙江省内”的火点，只在数据覆盖区域内计算归因比例；\n",
    "2) 省级窗口（近似，可替换为更精细的省历）：为黑龙江设置小麦/玉米的收获时间；\n",
    "3) 耕地邻近缓冲（~500m 等效）：对作物栅格做像素邻域搜索，捕捉田边焚烧；\n",
    "4) 重新分类并导出“覆盖区域内”的地图与统计。\n",
    "\n",
    "改进后的黑龙江区域结果：\n",
    "- likely_agri_burning ≈ 27.57%（与文献 15%–30% 区间一致）\n",
    "- 相比原始全国口径的 1.77%，这更能反映方法在“数据覆盖到位”的地区的真实性能。\n",
    "\n",
    "接下来若要得到“全国口径”的可信结论，建议：\n",
    "- 补充全国耕地/作物分布数据（或至少华北、华东等重点区），直接套用本改进版框架；\n",
    "- 或分省逐步补齐覆盖，最后合并各省的“覆盖区域内估计”形成全国估计。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改进实现：以黑龙江为例的覆盖感知 + 省级窗口 + 栅格邻域缓冲\n",
    "import os, math, warnings, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio import transform as rio_transform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams as _rc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 0) 兜底：获取 fire_gdf 与 counties\n",
    "if 'fire_gdf' not in globals():\n",
    "    # 如果内存中没有，就尝试从之前导出的点集加载（若存在）\n",
    "    pts_csv = Path(RESULTS_TASK2)/'ag_burning_classified_points.geojson'\n",
    "    if pts_csv.exists():\n",
    "        fire_gdf = gpd.read_file(pts_csv)\n",
    "    else:\n",
    "        raise RuntimeError('找不到 fire_gdf，请先运行上游生成火点数据的单元。')\n",
    "if 'counties' not in globals():\n",
    "    shp = Path(RAW_DIR)/'chn_county'\n",
    "    shp = next((shp/f for f in os.listdir(shp) if f.endswith('.shp')), None)\n",
    "    if shp is None:\n",
    "        raise RuntimeError('找不到县域矢量数据。')\n",
    "    counties = gpd.read_file(shp)\n",
    "if fire_gdf.crs is None:\n",
    "    fire_gdf = fire_gdf.set_crs(4326)\n",
    "elif fire_gdf.crs.to_epsg() != 4326:\n",
    "    fire_gdf = fire_gdf.to_crs(4326)\n",
    "if counties.crs is None:\n",
    "    counties = counties.set_crs(4326)\n",
    "elif counties.crs.to_epsg() != 4326:\n",
    "    counties = counties.to_crs(4326)\n",
    "\n",
    "# 1) 锁定黑龙江省区域多边形\n",
    "prov_col = '省级' if '省级' in counties.columns else ('NAME_1' if 'NAME_1' in counties.columns else None)\n",
    "if prov_col is None:\n",
    "    raise RuntimeError('无法识别县域数据中的省级字段（期望 省级 或 NAME_1）。')\n",
    "\n",
    "def _is_hlj(x):\n",
    "    s = str(x)\n",
    "    return ('黑龙江' in s) or ('Heilongjiang' in s) or ('Hēi Lóng Jiāng' in s)\n",
    "\n",
    "hlj_poly = counties[counties[prov_col].apply(_is_hlj)].dissolve().geometry.iloc[0]\n",
    "\n",
    "# 2) 仅取黑龙江内的火点（覆盖感知）\n",
    "# 使用几何关系直接筛选，避免构造临时 GeoDataFrame 导致的类型检查/兼容性问题\n",
    "hlj_poly = counties[counties[prov_col].apply(_is_hlj)].dissolve().geometry.unary_union\n",
    "# unary_union 会返回一个单一的 Geometry 对象（Polygon/MultiPolygon），适合用于 .within()\n",
    "hlj_fire = fire_gdf[fire_gdf.geometry.within(hlj_poly)].copy()\n",
    "hlj_fire = hlj_fire.drop(columns=[c for c in hlj_fire.columns if c.startswith('index_')], errors='ignore')\n",
    "print(f'黑龙江省内火点数: {len(hlj_fire):,}')\n",
    "\n",
    "# 3) 定义黑龙江作物收获窗口（近似）\n",
    "def _parse_date_col(df):\n",
    "    for c in ['ACQ_DATE','date','DATE','acq_date']:\n",
    "        if c in df.columns:\n",
    "            return pd.to_datetime(df[c], errors='coerce')\n",
    "    # 如果已有 year/month/day 列也可拼装\n",
    "    if set(['year','month','day']).issubset(df.columns):\n",
    "        return pd.to_datetime(df[['year','month','day']].rename(columns={'year':'Y','month':'M','day':'D'}).assign(Y=lambda d:d['Y'].astype(int),M=lambda d:d['M'].astype(int),D=lambda d:d['D'].astype(int)).apply(lambda r: f\"{int(r['Y']):04d}-{int(r['M']):02d}-{int(r['D']):02d}\", axis=1), errors='coerce')\n",
    "    raise RuntimeError('无法从火点数据中解析日期列。')\n",
    "\n",
    "hlj_fire = hlj_fire.copy()\n",
    "# 强制转换日期为 datetime\n",
    "if 'date' in hlj_fire.columns:\n",
    "    hlj_fire['date'] = pd.to_datetime(hlj_fire['date'], errors='coerce')\n",
    "else:\n",
    "    hlj_fire['date'] = _parse_date_col(hlj_fire)\n",
    "\n",
    "hlj_fire['month'] = hlj_fire['date'].dt.month\n",
    "hlj_fire['day'] = hlj_fire['date'].dt.day\n",
    "hlj_fire['year'] = hlj_fire['date'].dt.year\n",
    "\n",
    "# 省级窗口（可根据资料进一步细化）\n",
    "# 春小麦（HLJ）收割大致在 8/1-9/10，玉米在 9/25-11/10\n",
    "\n",
    "def in_window(m, d, sm, sd, em, ed):\n",
    "    import datetime as _dt\n",
    "    try:\n",
    "        t = _dt.date(2020, int(m), int(d))\n",
    "        a = _dt.date(2020, sm, sd)\n",
    "        b = _dt.date(2020, em, ed)\n",
    "        return (a <= t <= b)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "hlj_fire['in_wheat_window_hlj'] = [in_window(m, d, 8, 1, 9, 10) for m, d in zip(hlj_fire['month'], hlj_fire['day'])]\n",
    "hlj_fire['in_corn_window_hlj']  = [in_window(m, d, 9, 25, 11, 10) for m, d in zip(hlj_fire['month'], hlj_fire['day'])]\n",
    "hlj_fire['in_harvest_hlj'] = hlj_fire['in_wheat_window_hlj'] | hlj_fire['in_corn_window_hlj']\n",
    "\n",
    "# 4) 栅格邻域缓冲：针对 HLJ 每年小麦/玉米栅格，在像素邻域内搜索\n",
    "CROPLAND_BUFFER_M = int(os.environ.get('CROPLAND_BUFFER_M', 500))\n",
    "CROP_DIR = Path(RAW_DIR)/'cropland_distribution_and_phenological_data'\n",
    "\n",
    "def open_raster_safe(path: Path):\n",
    "    if not path.exists():\n",
    "        return None, None, None, None\n",
    "    src = rasterio.open(path)\n",
    "    arr = src.read(1)\n",
    "    ndv = src.nodata if src.nodata is not None else np.nan\n",
    "    finite = arr[np.isfinite(arr)] if np.isnan(ndv) else arr[arr != ndv]\n",
    "    vmax = float(np.nanmax(finite)) if finite.size>0 else 0.0\n",
    "    # 自适应阈值\n",
    "    thr = 0.2 if vmax<=1.0 else (20.0 if vmax>=100.0 else 0.2*vmax)\n",
    "    return src, arr, ndv, thr\n",
    "def meters_per_pixel(src):\n",
    "    # 估算像素大小：经纬度转米（按影像中心纬度）\n",
    "    T = src.transform\n",
    "    px_deg_x = abs(T.a)\n",
    "    px_deg_y = abs(T.e)\n",
    "    # 取影像中心纬度\n",
    "    c = rio_transform.xy(T, src.height//2, src.width//2)\n",
    "    lat = c[1] if isinstance(c, (tuple, list)) else 45.0\n",
    "    m_per_deg_lat = 111320.0\n",
    "    m_per_deg_lon = 111320.0 * math.cos(math.radians(lat))\n",
    "    mpx_x = px_deg_x * m_per_deg_lon\n",
    "    mpx_y = px_deg_y * m_per_deg_lat\n",
    "    return (mpx_x + mpx_y)/2.0\n",
    "    return (mpx_x + mpx_y)/2.0\n",
    "\n",
    "def buffered_hit_for_points(df_year, rasters):\n",
    "    # rasters: list of (src, arr, ndv, thr) for maize & wheat\n",
    "    if len(df_year)==0:\n",
    "        return np.array([], dtype=bool)\n",
    "    hits = np.zeros(len(df_year), dtype=bool)\n",
    "    for src, arr, ndv, thr in rasters:\n",
    "        if src is None:\n",
    "            continue\n",
    "        mpp = meters_per_pixel(src)\n",
    "        rad_px = max(1, int(round(CROPLAND_BUFFER_M / max(mpp,1e-6))))\n",
    "        # 将经纬度转为行列\n",
    "        rows_cols = [src.index(lon, lat) for lon, lat in zip(df_year.geometry.x, df_year.geometry.y)]\n",
    "        h, w = arr.shape\n",
    "        for i, (r, c) in enumerate(rows_cols):\n",
    "            if r<0 or r>=h or c<0 or c>=w:\n",
    "                continue\n",
    "            r0, r1 = max(0, r-rad_px), min(h, r+rad_px+1)\n",
    "            c0, c1 = max(0, c-rad_px), min(w, c+rad_px+1)\n",
    "            sub = arr[r0:r1, c0:c1]\n",
    "            if np.isnan(ndv):\n",
    "                valid = sub[np.isfinite(sub)]\n",
    "            else:\n",
    "                valid = sub[sub!=ndv]\n",
    "            if valid.size==0:\n",
    "                continue\n",
    "            if np.nanmax(valid) > thr:\n",
    "                hits[i] = True\n",
    "    return hits\n",
    "\n",
    "# 逐年处理 HLJ 火点\n",
    "hlj_fire = hlj_fire.copy()\n",
    "hlj_fire['is_cropland'] = hlj_fire.get('is_cropland', False)\n",
    "buf_hits_total = np.zeros(len(hlj_fire), dtype=bool)\n",
    "years = sorted([int(y) for y in pd.unique(hlj_fire['year'].dropna())])\n",
    "for y in years:\n",
    "    sub_idx = np.where(hlj_fire['year'].values==y)[0]\n",
    "    sub = hlj_fire.iloc[sub_idx]\n",
    "    maize = CROP_DIR/f'heilongjiang_maize_ma_{y}.tif'\n",
    "    wheat = CROP_DIR/f'heilongjiang_wheat_ma_{y}.tif'\n",
    "    rasters = []\n",
    "    for pth in [maize, wheat]:\n",
    "        src, arr, ndv, thr = open_raster_safe(pth)\n",
    "        rasters.append((src, arr, ndv, thr))\n",
    "    hits = buffered_hit_for_points(sub, rasters)\n",
    "    buf_hits_total[sub_idx] = hits\n",
    "for src, _, _, _ in rasters:\n",
    "    if src is not None:\n",
    "        try:\n",
    "            src.close()\n",
    "        except Exception as e:\n",
    "            print(f\"关闭 raster 时出错: {e}\")\n",
    "\n",
    "hlj_fire['is_cropland_buffered'] = hlj_fire['is_cropland'] | buf_hits_total\n",
    "\n",
    "# 5) 改进分类（HLJ 内）\n",
    "\n",
    "def classify_row(row):\n",
    "    on_crop = bool(row.get('is_cropland_buffered', False))\n",
    "    in_harv = bool(row.get('in_harvest_hlj', False))\n",
    "    if on_crop and in_harv:\n",
    "        return 'likely_agri_burning'\n",
    "    if on_crop and not in_harv:\n",
    "        return 'cropland_out_of_harvest'\n",
    "    if (not on_crop) and in_harv:\n",
    "        return 'non_cropland_in_harvest'\n",
    "    return 'other_or_uncertain'\n",
    "\n",
    "hlj_fire['label_improved'] = hlj_fire.apply(classify_row, axis=1)\n",
    "summary = (hlj_fire['label_improved'].value_counts().rename_axis('label').reset_index(name='count'))\n",
    "summary['percent'] = (summary['count']/summary['count'].sum()*100).round(2)\n",
    "print('HLJ 改进版汇总:')\n",
    "print(summary)\n",
    "\n",
    "# 6) 导出与地图\n",
    "out_dir = RESULTS_TASK2\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "summary_path = out_dir/'ag_burning_summary_hlj_improved.csv'\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print('保存:', summary_path)\n",
    "\n",
    "# 点图\n",
    "try:\n",
    "    _rc['font.sans-serif'] = ['Microsoft YaHei','SimHei','Noto Sans CJK SC','Arial'] + _rc.get('font.sans-serif', [])\n",
    "    base = counties.plot(color='lightgrey', edgecolor='white', linewidth=0.2, figsize=(7,7))\n",
    "    palette = {'likely_agri_burning':'#ff6b6b','cropland_out_of_harvest':'#ffa07a','non_cropland_in_harvest':'#8ecae6','other_or_uncertain':'#c0c0c0'}\n",
    "    for lab in ['other_or_uncertain','non_cropland_in_harvest','cropland_out_of_harvest','likely_agri_burning']:\n",
    "        sub = hlj_fire[hlj_fire['label_improved']==lab]\n",
    "        if len(sub)==0:\n",
    "            continue\n",
    "        sub.plot(ax=base, markersize=2 if lab!='likely_agri_burning' else 6, alpha=0.6 if lab!='likely_agri_burning' else 0.9, color=palette.get(lab,'grey'))\n",
    "    plt.title('黑龙江 火点分类（改进版）')\n",
    "    points_map = out_dir/'ag_burning_points_map_hlj_improved.png'\n",
    "    plt.savefig(points_map, dpi=180, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('保存:', points_map)\n",
    "except Exception as e:\n",
    "    print('绘制点图失败:', e)\n",
    "\n",
    "# 县域聚合与底图\n",
    "try:\n",
    "    key = '县级码' if '县级码' in counties.columns else ('code' if 'code' in counties.columns else None)\n",
    "    name_key = '县级' if '县级' in counties.columns else ('NAME_3' if 'NAME_3' in counties.columns else None)\n",
    "    if key is None or name_key is None:\n",
    "        raise RuntimeError('无法识别县级编码/名称字段。')\n",
    "    # 仅保留 HLJ 县域\n",
    "    hlj_counties = counties[counties[prov_col].apply(_is_hlj)].copy()\n",
    "    # 需要火点关联到县级：若先前没有，则做一次 within 关联\n",
    "    if 'county_code' not in hlj_fire.columns:\n",
    "        join = gpd.sjoin(hlj_fire, hlj_counties[[key, name_key, 'geometry']].rename(columns={key:'county_code', name_key:'county_name'}), predicate='within', how='left')\n",
    "    else:\n",
    "        join = hlj_fire\n",
    "    cnt = (join[join['label_improved']=='likely_agri_burning']\n",
    "           .groupby('county_code').size().rename('ag_burn_count').reset_index())\n",
    "    out_csv = out_dir/'county_ag_burning_counts_hlj_improved.csv'\n",
    "    cnt.to_csv(out_csv, index=False)\n",
    "    print('保存:', out_csv)\n",
    "    # 画县域热力图\n",
    "    hlj_counties = hlj_counties.merge(cnt, left_on=key, right_on='county_code', how='left')\n",
    "    hlj_counties['ag_burn_count'] = hlj_counties['ag_burn_count'].fillna(0)\n",
    "    ax = hlj_counties.plot(column='ag_burn_count', cmap='OrRd', linewidth=0.1, edgecolor='white', legend=True, figsize=(8,6))\n",
    "    plt.title('黑龙江 县域“农业焚烧”火点数（改进版）')\n",
    "    county_map = out_dir/'county_ag_burning_map_hlj_improved.png'\n",
    "    plt.savefig(county_map, dpi=180, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('保存:', county_map)\n",
    "except Exception as e:\n",
    "    print('县域热力图失败:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2ba30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3577b0f",
   "metadata": {},
   "source": [
    "## 任务3：长期时空趋势（黑龙江 2010–2019）\n",
    "本节仅聚焦黑龙江省（因数据覆盖局限），基于“改进版”的农业焚烧判定结果，评估：\n",
    "- 县级 2010–2019 年度“likely_agri_burning”趋势（Mann–Kendall 与 Sen 斜率）\n",
    "- 县级是否存在显著拐点（Pettitt 非参变点检验，单一突变）\n",
    "- 省级年度总量序列与潜在拐点\n",
    "所有结果保存至 `results/task3/`，并在 Notebook 内联显示关键图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务3实现：县级趋势与拐点（HLJ 2010–2019）\n",
    "import os, math, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams as _rc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 输出目录（定位到仓库根下的 results/task3）\n",
    "if 'REPO_ROOT' in globals():\n",
    "    _ROOT = REPO_ROOT\n",
    "else:\n",
    "    _ROOT = Path.cwd().resolve()\n",
    "    \n",
    "# ⚠️ 确保 _ROOT 是 Path 对象\n",
    "if not isinstance(_ROOT, Path):\n",
    "    _ROOT = Path(_ROOT)\n",
    "\n",
    "if _ROOT.name.lower() == 'script':\n",
    "    _ROOT = _ROOT.parent\n",
    "RESULTS_TASK3 = (_ROOT / 'results' / 'task3')\n",
    "RESULTS_TASK3.mkdir(parents=True, exist_ok=True)\n",
    "print('Task3 输出目录:', RESULTS_TASK3)\n",
    "\n",
    "# 复用已有 counties、hlj_fire（若不存在则快速构建 HLJ 子集）\n",
    "def _ensure_hlj_fire_with_labels():\n",
    "    # ⚠️ 修复：移除 global 声明，避免未定义变量\n",
    "    # global hlj_fire, counties\n",
    "    \n",
    "    # 1) counties\n",
    "    if 'counties' not in globals():\n",
    "        # ⚠️ 修复：确保 shp_dir 是 Path 对象并检查存在性\n",
    "        shp_dir = _ROOT / 'raw_data' / 'chn_county'\n",
    "        if not isinstance(shp_dir, Path):\n",
    "            shp_dir = Path(shp_dir)\n",
    "        \n",
    "        if not shp_dir.exists():\n",
    "            raise FileNotFoundError(f\"县界目录不存在: {shp_dir}\")\n",
    "        \n",
    "        # ⚠️ 修复：安全地查找 shapefile\n",
    "        shp_files = list(shp_dir.glob('*.shp'))\n",
    "        if not shp_files:\n",
    "            raise FileNotFoundError(f\"在 {shp_dir} 中未找到 .shp 文件\")\n",
    "        \n",
    "        shp = shp_files[0]  # 取第一个找到的 shp 文件\n",
    "        counties_local = gpd.read_file(shp)\n",
    "    else:\n",
    "        # ⚠️ 修复：确保 counties 是有效的 GeoDataFrame\n",
    "        counties_local = globals()['counties']  # 使用 globals() 安全访问\n",
    "    if counties_local.crs is None:\n",
    "        counties_local = counties_local.set_crs(4326)\n",
    "    elif counties_local.crs.to_epsg()!=4326:\n",
    "        counties_local = counties_local.to_crs(4326)\n",
    "    prov_col = '省级' if '省级' in counties_local.columns else ('NAME_1' if 'NAME_1' in counties_local.columns else None)\n",
    "    if prov_col is None:\n",
    "        # ⚠️ 修复：如果没有找到省级列，尝试其他常见列名\n",
    "        possible_cols = ['province', 'PROVINCE', 'Province', 'name_1', 'NAME_1']\n",
    "        for col in possible_cols:\n",
    "            if col in counties_local.columns:\n",
    "                prov_col = col\n",
    "                break\n",
    "        if prov_col is None:\n",
    "            raise ValueError(\"无法找到省级列，请检查县界文件的列名\")\n",
    "        \n",
    "    def _is_hlj(x):\n",
    "        s=str(x); return ('黑龙江' in s) or ('Heilongjiang' in s) or ('Hēi Lóng Jiāng' in s)\n",
    "    \n",
    "    # ⚠️ 修复：添加安全检查，确保有黑龙江数据\n",
    "    hlj_mask = counties_local[prov_col].apply(_is_hlj)\n",
    "    if not hlj_mask.any():\n",
    "        raise ValueError(\"在县界数据中未找到黑龙江相关区域\")\n",
    "    \n",
    "    hlj_poly = counties_local[hlj_mask].dissolve().geometry.iloc[0]\n",
    "    \n",
    "    # 2) fire\n",
    "    # ⚠️ 修复：安全检查 hlj_fire 变量\n",
    "    if 'hlj_fire' in globals() and globals()['hlj_fire'] is not None and hasattr(globals()['hlj_fire'], 'columns') and ('label_improved' in globals()['hlj_fire'].columns):\n",
    "        return globals()['hlj_fire'], counties_local, prov_col\n",
    "    \n",
    "    if 'fire_gdf' in globals():\n",
    "        fire_local = globals()['fire_gdf'].copy()\n",
    "    else:\n",
    "        # 从改进版或通用导出回读（可能不含 label_improved，仅用于定位 HLJ 范围）\n",
    "        gpath = _ROOT / 'results' / 'task2' / 'ag_burning_classified_points.geojson'\n",
    "        if not gpath.exists():\n",
    "            raise RuntimeError('找不到 fire_gdf，请先运行任务2改进版或生成火点数据单元。')\n",
    "        fire_local = gpd.read_file(gpath)\n",
    "    if fire_local.crs is None:\n",
    "        fire_local = fire_local.set_crs(4326)\n",
    "    elif fire_local.crs.to_epsg()!=4326:\n",
    "        fire_local = fire_local.to_crs(4326)\n",
    "    \n",
    "    # ⚠️ 修复：使用正确的 GeoDataFrame 构造方式\n",
    "    hlj_region = gpd.GeoDataFrame([{'geometry': hlj_poly}], crs=4326)\n",
    "    hlj_fire_local = gpd.sjoin(fire_local, hlj_region, predicate='within', how='inner')\n",
    "    \n",
    "    hlj_fire_local = hlj_fire_local.drop(columns=[c for c in hlj_fire_local.columns if c.startswith('index_')], errors='ignore')\n",
    "    \n",
    "    # 兜底：确保 year 存在\n",
    "    if 'date' in hlj_fire_local.columns:\n",
    "        hlj_fire_local['date'] = pd.to_datetime(hlj_fire_local['date'], errors='coerce')\n",
    "    elif 'ACQ_DATE' in hlj_fire_local.columns:\n",
    "        hlj_fire_local['date'] = pd.to_datetime(hlj_fire_local['ACQ_DATE'], errors='coerce')\n",
    "    else:\n",
    "        raise RuntimeError('无法解析日期列以计算年度。')\n",
    "    hlj_fire_local['year'] = hlj_fire_local['date'].dt.year\n",
    "    \n",
    "    # 若不存在改进标签，则尽量复用已有列（降级策略：in_harvest 或原 label）\n",
    "    if 'label_improved' not in hlj_fire_local.columns:\n",
    "        if 'label' in hlj_fire_local.columns:\n",
    "            hlj_fire_local['label_improved'] = hlj_fire_local['label']\n",
    "        else:\n",
    "            in_cols = [c for c in hlj_fire_local.columns if 'in_harvest' in c]\n",
    "            if len(in_cols)>0:\n",
    "                col = in_cols[0]\n",
    "                hlj_fire_local['label_improved'] = np.where(hlj_fire_local[col].astype(bool),'likely_agri_burning','other_or_uncertain')\n",
    "            else:\n",
    "                raise RuntimeError('找不到可用的农业焚烧标签（label_improved/label/in_harvest*）。')\n",
    "    \n",
    "    return hlj_fire_local, counties_local, prov_col\n",
    "\n",
    "hlj_fire3, counties3, prov_col3 = _ensure_hlj_fire_with_labels()\n",
    "print('HLJ 点数量:', len(hlj_fire3))\n",
    "\n",
    "# 关联县级编码\n",
    "key = '县级码' if '县级码' in counties3.columns else ('code' if 'code' in counties3.columns else None)\n",
    "name_key = '县级' if '县级' in counties3.columns else ('NAME_3' if 'NAME_3' in counties3.columns else None)\n",
    "\n",
    "# ⚠️ 修复：添加安全检查\n",
    "if key is None:\n",
    "    possible_keys = ['COUNTY_CODE', 'adcode', 'ADCODE', 'County_Code', 'county_code', 'code']\n",
    "    for col in possible_keys:\n",
    "        if col in counties3.columns:\n",
    "            key = col\n",
    "            break\n",
    "    if key is None:\n",
    "        raise ValueError(\"无法找到县级编码列，请检查县界文件的列名\")\n",
    "\n",
    "if name_key is None:\n",
    "    possible_names = ['COUNTY_NAME', 'name', 'NAME', 'County_Name', 'county_name', 'NAME_3']\n",
    "    for col in possible_names:\n",
    "        if col in counties3.columns:\n",
    "            name_key = col\n",
    "            break\n",
    "    if name_key is None:\n",
    "        raise ValueError(\"无法找到县级名称列，请检查县界文件的列名\")\n",
    "\n",
    "hlj_counties = counties3[counties3[prov_col3].apply(lambda x: ('黑龙江' in str(x)) or ('Heilongjiang' in str(x)) or ('Hēi Lóng Jiāng' in str(x)))].copy()\n",
    "join = gpd.sjoin(hlj_fire3, hlj_counties[[key, name_key, 'geometry']].rename(columns={key:'county_code', name_key:'county_name'}), predicate='within', how='left')\n",
    "\n",
    "# 县-年 计数（仅 likely_agri_burning）\n",
    "sub = join[join['label_improved']=='likely_agri_burning'].copy()\n",
    "cnt = (sub.groupby(['county_code','county_name','year']).size().rename('count').reset_index())\n",
    "# 填补 2010–2019 缺失年份为 0\n",
    "all_years = list(range(2010, 2020))\n",
    "rows = []\n",
    "for code, g in cnt.groupby('county_code'):\n",
    "    name = g['county_name'].iloc[0] if 'county_name' in g.columns else None\n",
    "    y2c = dict(zip(g['year'], g['count']))\n",
    "    for y in all_years:\n",
    "        rows.append({'county_code':code,'county_name':name,'year':y,'count':int(y2c.get(y,0))})\n",
    "cnt_full = pd.DataFrame(rows)\n",
    "out_counts = RESULTS_TASK3/'hlj_county_year_likely_agri_counts.csv'\n",
    "cnt_full.to_csv(out_counts, index=False, encoding='utf-8-sig')\n",
    "print('保存:', out_counts)\n",
    "\n",
    "# 统计学工具：Mann-Kendall、Sen's slope、Pettitt\n",
    "from math import sqrt\n",
    "from itertools import combinations\n",
    "\n",
    "def mk_test(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    n = len(x)\n",
    "    S = 0\n",
    "    for i in range(n-1):\n",
    "        S += np.sum(np.sign(x[i+1:]-x[i]))\n",
    "    varS = (n*(n-1)*(2*n+5))/18\n",
    "    z = 0\n",
    "    if S>0: z = (S-1)/sqrt(varS)\n",
    "    elif S<0: z = (S+1)/sqrt(varS)\n",
    "    from math import erf\n",
    "    p = 2*(1-0.5*(1+erf(abs(z)/sqrt(2))))\n",
    "    trend = 'increasing' if z>0 and p<0.05 else ('decreasing' if z<0 and p<0.05 else 'no-trend')\n",
    "    return {'S':S,'z':z,'p':p,'trend':trend}\n",
    "\n",
    "def sen_slope(x, years):\n",
    "    pairs = []\n",
    "    for (i, xi),(j, xj) in combinations(list(enumerate(x)), 2):\n",
    "        if years[j]==years[i]:\n",
    "            continue\n",
    "        pairs.append((xj - xi)/ (years[j]-years[i]))\n",
    "    if len(pairs)==0:\n",
    "        return 0.0\n",
    "    return float(np.median(pairs))\n",
    "\n",
    "def pettitt_test(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    n = x.size\n",
    "    if n<2:\n",
    "        return (None, 1.0)\n",
    "    U = np.zeros(n)\n",
    "    for t in range(n):\n",
    "        s = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1):\n",
    "                if j<=t and i>t:\n",
    "                    s += np.sign(x[i]-x[j])\n",
    "        U[t] = s\n",
    "    K = int(np.argmax(np.abs(U)))\n",
    "    Kmax = np.max(np.abs(U))\n",
    "    p = 2*np.exp((-6*(Kmax**2))/(n**3+n**2))\n",
    "    return (K if p<0.05 else None, float(p))\n",
    "\n",
    "# 对每个县做趋势与拐点\n",
    "rows = []\n",
    "for code, g in cnt_full.groupby('county_code'):\n",
    "    g = g.sort_values('year')\n",
    "    y = g['year'].tolist()\n",
    "    v = g['count'].astype(float).tolist()\n",
    "    mk = mk_test(v)\n",
    "    slope = sen_slope(v, y)\n",
    "    cp_idx, cp_p = pettitt_test(v)\n",
    "    cp_year = int(y[cp_idx]) if cp_idx is not None else None\n",
    "    pre_mean = float(np.mean(v[:cp_idx+1])) if cp_idx is not None else np.nan\n",
    "    post_mean = float(np.mean(v[cp_idx+1:])) if cp_idx is not None else np.nan\n",
    "    rows.append({'county_code':code,'county_name':g['county_name'].iloc[0],\n",
    "                 'mk_trend':mk['trend'],'mk_p':mk['p'],'sen_slope':slope,\n",
    "                 'change_year':cp_year,'change_p':cp_p,'pre_mean':pre_mean,'post_mean':post_mean})\n",
    "summary = pd.DataFrame(rows)\n",
    "out_summary = RESULTS_TASK3/'hlj_county_trend_summary.csv'\n",
    "summary.to_csv(out_summary, index=False, encoding='utf-8-sig')\n",
    "print('保存:', out_summary)\n",
    "\n",
    "# 省级年度序列与拐点\n",
    "prov_series = cnt_full.groupby('year')['count'].sum().reset_index()\n",
    "prov_series_path = RESULTS_TASK3/'hlj_province_series.csv'\n",
    "prov_series.to_csv(prov_series_path, index=False, encoding='utf-8-sig')\n",
    "cp_idx_p, cp_pv = pettitt_test(prov_series['count'].values)\n",
    "cp_year_p = int(prov_series['year'].iloc[cp_idx_p]) if cp_idx_p is not None else None\n",
    "print('省级总量：变点年份=', cp_year_p, ' p=', round(cp_pv,4))\n",
    "\n",
    "# 可视化\n",
    "_rc['font.sans-serif'] = ['Microsoft YaHei','SimHei','Noto Sans CJK SC','Arial'] + _rc.get('font.sans-serif', [])\n",
    "fig, ax = plt.subplots(1,1, figsize=(7,4))\n",
    "ax.plot(prov_series['year'], prov_series['count'], marker='o')\n",
    "if cp_year_p is not None:\n",
    "    ax.axvline(cp_year_p, color='red', ls='--', label=f'Change {cp_year_p}')\n",
    "ax.set_title('黑龙江 全省 likely_agri_burning 年度总量（2010–2019）')\n",
    "ax.set_xlabel('Year'); ax.set_ylabel('Count')\n",
    "ax.legend(loc='upper left')\n",
    "png = RESULTS_TASK3/'hlj_province_series.png'\n",
    "plt.savefig(png, dpi=180, bbox_inches='tight'); plt.show(); plt.close()\n",
    "print('保存:', png)\n",
    "\n",
    "# 地图：Sen 斜率与变点年份\n",
    "gmap = hlj_counties.merge(summary, left_on=key, right_on='county_code', how='left')\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "gmap.plot(column='sen_slope', cmap='RdBu_r', legend=True, linewidth=0.1, edgecolor='white', ax=ax, vmin=-40, vmax=40)\n",
    "ax.set_title('黑龙江 县域 Sen 斜率（likely_agri_burning，2010–2019）')\n",
    "png = RESULTS_TASK3/'hlj_sen_slope_map.png'\n",
    "plt.savefig(png, dpi=180, bbox_inches='tight'); plt.show(); plt.close()\n",
    "print('保存:', png)\n",
    "\n",
    "# 变点年份：若没有显著变点，给出信息化底图\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "if gmap['change_year'].notna().sum() > 0:\n",
    "    gmap.plot(column='change_year', cmap='viridis', legend=True, linewidth=0.1, edgecolor='white', ax=ax)\n",
    "    ax.set_title('黑龙江 县域 变点年份（Pettitt，p<0.05 为显著）')\n",
    "else:\n",
    "    gmap.plot(color='#f2f2f2', edgecolor='white', linewidth=0.1, ax=ax)\n",
    "    ax.set_title('黑龙江 县域：未检测到显著变点（p<0.05）')\n",
    "    # 输出说明文件\n",
    "    with open(RESULTS_TASK3/'no_significant_change_points.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('Pettitt 检验在县域尺度未检测到显著变点（p<0.05）。\\n')\n",
    "png = RESULTS_TASK3/'hlj_change_year_map.png'\n",
    "plt.savefig(png, dpi=180, bbox_inches='tight'); plt.show(); plt.close()\n",
    "print('保存:', png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0151996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务3小结与概览（统计汇总与TOP榜）\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams as _rc\n",
    "_rc['font.sans-serif'] = ['Microsoft YaHei','SimHei','Noto Sans CJK SC','Arial'] + _rc.get('font.sans-serif', [])\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name.lower()=='script':\n",
    "    ROOT = ROOT.parent\n",
    "TASK3 = ROOT/'results'/'task3'\n",
    "df = pd.read_csv(TASK3/'hlj_county_trend_summary.csv')\n",
    "# 概览计数\n",
    "overview = (df['mk_trend'].value_counts().rename_axis('mk_trend').reset_index(name='count'))\n",
    "overview['percent'] = (overview['count']/overview['count'].sum()*100).round(1)\n",
    "print('MK 趋势概览:\\n', overview)\n",
    "# Top榜（按 Sen 斜率）\n",
    "top_dec = df.sort_values('sen_slope').head(10)[['county_name','sen_slope','mk_trend','mk_p']]\n",
    "top_inc = df.sort_values('sen_slope', ascending=False).head(10)[['county_name','sen_slope','mk_trend','mk_p']]\n",
    "top_dec.to_csv(TASK3/'top10_decreasing_counties.csv', index=False, encoding='utf-8-sig')\n",
    "top_inc.to_csv(TASK3/'top10_increasing_counties.csv', index=False, encoding='utf-8-sig')\n",
    "print('保存: top10_decreasing_counties.csv, top10_increasing_counties.csv')\n",
    "\n",
    "# 斜率分布图\n",
    "fig, ax = plt.subplots(1,1, figsize=(7,4))\n",
    "ax.hist(df['sen_slope'].fillna(0), bins=25, color='#6baed6', edgecolor='white')\n",
    "ax.set_title('县域 Sen 斜率分布（likely_agri_burning，2010–2019）')\n",
    "ax.set_xlabel('Sen slope (count per year)'); ax.set_ylabel('Number of counties')\n",
    "png = TASK3/'hlj_sen_slope_hist.png'\n",
    "plt.savefig(png, dpi=180, bbox_inches='tight'); plt.show(); plt.close()\n",
    "print('保存:', png)\n",
    "overview.to_csv(TASK3/'hlj_task3_overview.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c988c70",
   "metadata": {},
   "source": [
    "## 任务3结果解读与改进建议（黑龙江 2010–2019）\n",
    "本节对上方产物做一个可交付级的简要结论，并说明改进方向。\n",
    "\n",
    "结论要点：\n",
    "- 省级年度总量：2014–2015 达到峰值，2016 起显著回落；Pettitt 检验未给出显著的单一突变年份（p≈0.495），但走势与禁烧治理强化的时间线相符。\n",
    "- 县级趋势（likely_agri_burning，2010–2019）：\n",
    "  - Mann–Kendall：多数县“无显著趋势”（~96%），有少量县显著下降，极少数显著上升。\n",
    "  - Sen 斜率空间格局：以负斜率为主，显示“多数县在下降”，与省级走势一致。\n",
    "- 变点检测（县级）：严格阈值 p<0.05 下，多数县未检出显著变点；说明变化更像“缓慢下降”或“多段渐变”，而非统一时间点的突变。\n",
    "\n",
    "为何显著性偏弱：\n",
    "- 时间样本较短（10年）且波动较大（2010–2015 高位、2016 以后快速回落），在非参检验中较难判定为“单调显著”。\n",
    "- 2018–2019 点数极低，拉低末期，导致分布非正态且存在零膨胀，对 MK 检验的功效不利。\n",
    "\n",
    "与文献的一致性：\n",
    "- 文献普遍报告“禁烧政策后焚烧显著减少”。本结果的省级曲线与大多数研究一致；县域 Sen 斜率以负为主也支撑“总体下降”。\n",
    "- 但“显著县比例较低”与样本年限、零膨胀和年内时序聚集有关，需要采用更针对性的统计方法来增强检出力。\n",
    "\n",
    "改进建议（可选增强，按优先级）：\n",
    "1) 季节化/窗口聚焦的趋势：仅对“收获窗口内”的农业焚烧计数做年度序列（已具备标签，可直接派生），减少非农业/非窗口噪声。\n",
    "2) 零膨胀稳健检验：采用季节 Kendall、预白化 MK（Hamed–Rao）、或基于泊松/负二项的广义线性趋势检验；给出 Sen 斜率的 bootstrap 置信区间。\n",
    "3) 频率与强度拆分：分别对“火点次数”和“高强度阈值（如FRP分位）”做趋势与变点，识别强度结构性变化。\n",
    "4) 变点更丰富的模型：尝试 binary segmentation / PELT / Bai–Perron 多变点检测（年数虽少，但可作启发式），并与政策节点对照。\n",
    "5) 归一化口径：用县域耕地面积归一化（若可获得），输出“单位耕地的焚烧强度”趋势，减小行政区面积差影响。\n",
    "\n",
    "交付物索引（results/task3）：\n",
    "- hlj_county_year_likely_agri_counts.csv：县×年农业焚烧计数\n",
    "- hlj_county_trend_summary.csv：县级 MK/Sen/Pettitt 摘要\n",
    "- hlj_province_series.csv / .png：省级年度序列与图\n",
    "- hlj_sen_slope_map.png：县域 Sen 斜率地图\n",
    "- hlj_change_year_map.png：县域变点年份地图（无显著时为提示底图）\n",
    "- top10_decreasing_counties.csv / top10_increasing_counties.csv：按 Sen 斜率排序的 Top 榜\n",
    "- hlj_sen_slope_hist.png：县域 Sen 斜率分布直方图\n",
    "\n",
    "备注：如需我将“季节化窗口趋势 + 预白化MK + bootstrap CI”落地为代码单元并生成补充图表，请告诉我优先级（省级或县级），我会直接新增并导出至 results/task3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务3增强：Sen 斜率置信区间（支持90%与95%）+ 显著性地图 + 省级最佳切点\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "from matplotlib import rcParams as _rc\n",
    "\n",
    "# 设置中文字体\n",
    "_rc['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei', 'Noto Sans CJK SC'] + _rc.get('font.sans-serif', [])\n",
    "\n",
    "# 开关：是否计算 Theil–Sen 置信区间与是否绘制显著性地图\n",
    "COMPUTE_SEN_CI = False   # 用户反馈90%仍全灰 -> 默认不再计算CI（可改为True开启）\n",
    "SHOW_CI_SIGNIFICANCE_MAP = False  # 默认不绘制显著性地图（可改为True开启）\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name.lower() == 'script': \n",
    "    ROOT = ROOT.parent\n",
    "TASK3 = ROOT / 'results' / 'task3'\n",
    "TASK3.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 读取数据\n",
    "cnt_full_path = TASK3 / 'hlj_county_year_likely_agri_counts.csv'\n",
    "if not cnt_full_path.exists():\n",
    "    raise FileNotFoundError(f\"找不到文件: {cnt_full_path}\")\n",
    "cnt_full = pd.read_csv(cnt_full_path)\n",
    "\n",
    "trend_path = TASK3 / 'hlj_county_trend_summary.csv'\n",
    "if not trend_path.exists():\n",
    "    raise FileNotFoundError(f\"找不到文件: {trend_path}\")\n",
    "trend = pd.read_csv(trend_path)\n",
    "\n",
    "# 1) Theil–Sen 斜率的经验置信区间\n",
    "if COMPUTE_SEN_CI:\n",
    "    CI_LEVELS = [0.90, 0.95]\n",
    "    rows = []\n",
    "    for code, g in cnt_full.groupby('county_code'):\n",
    "        g = g.sort_values('year')\n",
    "        y = g['year'].values\n",
    "        v = g['count'].astype(float).values\n",
    "        slopes = []\n",
    "        for (i, j) in combinations(range(len(y)), 2):\n",
    "            if y[j] == y[i]:\n",
    "                continue\n",
    "            slopes.append((v[j] - v[i]) / (y[j] - y[i]))\n",
    "        rec = {'county_code': code}\n",
    "        if len(slopes) == 0:\n",
    "            rec.update({'sen_slope_med': 0.0})\n",
    "            for lvl in CI_LEVELS:\n",
    "                rec.update({f'sen_slope_lo_{int(lvl*100)}': 0.0, f'sen_slope_hi_{int(lvl*100)}': 0.0})\n",
    "        else:\n",
    "            slopes = np.array(slopes, dtype=float)\n",
    "            rec['sen_slope_med'] = float(np.median(slopes))\n",
    "            for lvl in CI_LEVELS:\n",
    "                alpha = 1.0 - lvl\n",
    "                lo = float(np.percentile(slopes, (alpha/2)*100.0))\n",
    "                hi = float(np.percentile(slopes, (1.0 - alpha/2)*100.0))\n",
    "                rec.update({f'sen_slope_lo_{int(lvl*100)}': lo, f'sen_slope_hi_{int(lvl*100)}': hi})\n",
    "        rows.append(rec)\n",
    "    sen_ci = pd.DataFrame(rows)\n",
    "    enh = trend.merge(sen_ci, on='county_code', how='left')\n",
    "\n",
    "    def _sig_by_cols(row, lo_col, hi_col):\n",
    "        hi = row.get(hi_col, np.nan)\n",
    "        lo = row.get(lo_col, np.nan)\n",
    "        if pd.notna(hi) and hi < 0:\n",
    "            return 'significant_decrease'\n",
    "        if pd.notna(lo) and lo > 0:\n",
    "            return 'significant_increase'\n",
    "        return 'not_significant'\n",
    "\n",
    "    enh['sen_significance_95'] = enh.apply(lambda r: _sig_by_cols(r, 'sen_slope_lo_95', 'sen_slope_hi_95'), axis=1)\n",
    "    enh['sen_significance_90'] = enh.apply(lambda r: _sig_by_cols(r, 'sen_slope_lo_90', 'sen_slope_hi_90'), axis=1)\n",
    "    # 兼容旧列名\n",
    "    if 'sen_slope_lo_95' in enh.columns:\n",
    "        enh['sen_slope_lo'] = enh['sen_slope_lo_95']\n",
    "        enh['sen_slope_hi'] = enh['sen_slope_hi_95']\n",
    "    enh['sen_significance'] = enh.get('sen_significance_90', 'not_significant')\n",
    "else:\n",
    "    # 不计算CI：直接把 trend 作为增强版导出\n",
    "    enh = trend.copy()\n",
    "\n",
    "enh_path = TASK3 / 'hlj_county_trend_summary_enhanced.csv'\n",
    "enh.to_csv(enh_path, index=False, encoding='utf-8-sig')\n",
    "print('保存:', enh_path)\n",
    "\n",
    "# 2) 显著性地图\n",
    "if SHOW_CI_SIGNIFICANCE_MAP and COMPUTE_SEN_CI:\n",
    "    shp_dir = ROOT / 'raw_data' / 'chn_county'\n",
    "    if not shp_dir.exists():\n",
    "        raise FileNotFoundError(f\"县界目录不存在: {shp_dir}\")\n",
    "    \n",
    "    shp_files = list(shp_dir.glob('*.shp'))\n",
    "    if not shp_files:\n",
    "        raise FileNotFoundError(f\"在 {shp_dir} 中未找到 .shp 文件\")\n",
    "    \n",
    "    shp = shp_files[0]\n",
    "    counties = gpd.read_file(shp)\n",
    "    prov_col = '省级' if '省级' in counties.columns else ('NAME_1' if 'NAME_1' in counties.columns else None)\n",
    "    if prov_col is None:\n",
    "        possible_cols = ['province', 'PROVINCE', 'Province', 'name_1', 'NAME_1']\n",
    "        for col in possible_cols:\n",
    "            if col in counties.columns:\n",
    "                prov_col = col\n",
    "                break\n",
    "        if prov_col is None:\n",
    "            raise ValueError(\"无法找到省级列，请检查县界文件的列名\")\n",
    "        \n",
    "    def _is_hlj(x):\n",
    "        s = str(x)\n",
    "        return ('黑龙江' in s) or ('Heilongjiang' in s) or ('Hēi Lóng Jiāng' in s)\n",
    "\n",
    "    hlj_counties = counties[counties[prov_col].apply(_is_hlj)].copy()\n",
    "    key = '县级码' if '县级码' in hlj_counties.columns else ('code' if 'code' in hlj_counties.columns else None)\n",
    "    if key is None:\n",
    "        possible_keys = ['COUNTY_CODE', 'adcode', 'ADCODE', 'County_Code', 'county_code', 'code']\n",
    "        for col in possible_keys:\n",
    "            if col in hlj_counties.columns:\n",
    "                key = col\n",
    "                break\n",
    "        if key is None:\n",
    "            raise ValueError(\"无法找到县级编码列，请检查县界文件的列名\")\n",
    "\n",
    "    gmap = hlj_counties.merge(enh, left_on=key, right_on='county_code', how='left')\n",
    "    palette = {'significant_decrease': '#c44e52', 'significant_increase': '#4c72b0', 'not_significant': '#dddddd'}\n",
    "\n",
    "    def _plot_sig_map(sig_col: str, title: str, out_name: str):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        for lab in ['not_significant', 'significant_decrease', 'significant_increase']:\n",
    "            sub = gmap[gmap[sig_col] == lab]\n",
    "            if len(sub) > 0:\n",
    "                sub.plot(ax=ax, color=palette[lab], edgecolor='white', linewidth=0.1, label=lab.replace('_', ' '))\n",
    "        ax.set_title(title)\n",
    "        ax.legend(frameon=False, loc='lower left')\n",
    "        png = TASK3 / out_name\n",
    "        plt.savefig(png, dpi=180, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        print('保存:', png)\n",
    "\n",
    "    _plot_sig_map('sen_significance_90', '黑龙江 县域 Theil–Sen 斜率90%置信区间显著性', 'hlj_sen_significance_map_ci90.png')\n",
    "    _plot_sig_map('sen_significance_95', '黑龙江 县域 Theil–Sen 斜率95%置信区间显著性', 'hlj_sen_significance_map_ci95.png')\n",
    "else:\n",
    "    print('显著性地图已关闭（SHOW_CI_SIGNIFICANCE_MAP=False 或未计算CI）。')\n",
    "\n",
    "# 3) 省级最佳切点（两段均值 SSE 最小）\n",
    "prov = cnt_full.groupby('year')['count'].sum().reset_index().sort_values('year')\n",
    "if len(prov) == 0:\n",
    "    raise RuntimeError('省级年度序列数据为空，无法计算最佳切点。')\n",
    "\n",
    "# 数据清洗和类型转换\n",
    "prov['year'] = pd.to_numeric(prov['year'], errors='coerce')\n",
    "prov['count'] = pd.to_numeric(prov['count'], errors='coerce')\n",
    "\n",
    "# 移除空值\n",
    "prov = prov.dropna(subset=['year', 'count'])\n",
    "\n",
    "if len(prov) < 3:\n",
    "    print('年度数据点不足，无法计算最佳切点。(至少需要3个年份)')\n",
    "    best = {'year': None, 'sse': np.inf, 'pre_mean': np.nan, 'post_mean': np.nan, 'delta': np.nan}\n",
    "else:\n",
    "    years = prov['year'].values\n",
    "    vals = prov['count'].values\n",
    "    \n",
    "    # 确保数据是数值类型\n",
    "    years = years.astype(float)\n",
    "    vals = vals.astype(float)\n",
    "    \n",
    "    best = {'year': None, 'sse': np.inf, 'pre_mean': np.nan, 'post_mean': np.nan, 'delta': np.nan}\n",
    "\n",
    "    for k in range(1, len(years)-1):\n",
    "        pre = vals[:k]\n",
    "        post = vals[k:]\n",
    "        \n",
    "        # 确保数据是 numpy array 并且没有空值\n",
    "        pre = np.array(pre, dtype=float)\n",
    "        post = np.array(post, dtype=float)\n",
    "        \n",
    "        if len(pre) > 0 and len(post) > 0 and not np.any(np.isnan(pre)) and not np.any(np.isnan(post)):\n",
    "            pre_mean = np.mean(pre)\n",
    "            post_mean = np.mean(post)\n",
    "            sse = np.sum((pre - pre_mean)**2) + np.sum((post - post_mean)**2)\n",
    "            \n",
    "            if sse < best['sse']:\n",
    "                best.update({\n",
    "                    'year': int(years[k]),\n",
    "                    'sse': float(sse),\n",
    "                    'pre_mean': float(pre_mean),\n",
    "                    'post_mean': float(post_mean),\n",
    "                    'delta': float(post_mean - pre_mean)\n",
    "                })\n",
    "\n",
    "best_df = pd.DataFrame([best])\n",
    "best_path = TASK3 / 'hlj_province_best_split.csv'\n",
    "best_df.to_csv(best_path, index=False, encoding='utf-8-sig')\n",
    "print('保存:', best_path)\n",
    "\n",
    "# 绘图\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "\n",
    "if len(prov) > 0:\n",
    "    # 确保数据是数值类型\n",
    "    plot_years = prov['year'].values.astype(float)\n",
    "    plot_vals = prov['count'].values.astype(float)\n",
    "    \n",
    "    ax.plot(plot_years, plot_vals, marker='o')\n",
    "    \n",
    "    if best['year'] is not None:\n",
    "        ax.axvline(best['year'], color='red', ls='--', label=f\"Best split {best['year']}\")\n",
    "        \n",
    "    ax.set_title('黑龙江 省级年度序列与最佳切点（两段均值）')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(loc='upper left')\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No data available', ha='center', va='center', transform=ax.transAxes)\n",
    "    print('省级年度序列数据为空，无法绘制图表。')\n",
    "\n",
    "png = TASK3 / 'hlj_province_series_best_split.png'\n",
    "plt.savefig(png, dpi=180, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('保存:', png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce5c9b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
